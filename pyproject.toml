[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "videoannotator"
version = "1.0.0"
description = "A modern, modular toolkit for analyzing, processing, and visualizing human interaction videos"
readme = "README.md"
license = {text = "MIT"}
authors = [
    {name = "VideoAnnotator Team", email = "info@videoannotator.com"}
]
classifiers = [
    "Development Status :: 4 - Beta",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research", 
    "License :: OSI Approved :: MIT License",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.8",
    "Programming Language :: Python :: 3.9",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Multimedia :: Video",
    "Topic :: Scientific/Engineering :: Image Processing",
]
requires-python = ">=3.8"
dependencies = [
    # Core dependencies
    "fastapi>=0.115.0",
    "ipython>=8.12.3",
    "librosa>=0.10.0",
    "matplotlib>=3.9.0",
    "moviepy>=1.0.3",
    "opencv-python>=4.10.0",
    "openai-whisper>=20231117",
    "openpyxl",
    "pandas>=2.2.0",
    "Pillow>=10.4.0",
    "pytest>=8.3.0",
    "python-dotenv>=1.0.0",
    "numpy>=1.24.0",
    "tqdm>=4.65.0",
    
    # Audio processing
    "pyannote.audio>=3.3.0",
    "pyannote.core>=5.0.0",
    "pyannote.database>=5.1.0",
    "pyannote.metrics>=3.2.0",
    "pyannote.pipeline>=3.0.0",
    "speechbrain>=0.5.14",
    "torchaudio>=2.0.0",
    
    # Video and computer vision
    "ultralytics>=8.3.0",
    "supervision>=0.16.0",
    "torch>=2.0.0",
    "torchvision>=0.15.0",
    "timm>=0.9.0",
    
    # Scene detection and video understanding
    "scenedetect[opencv]>=0.6.3",
    "transformers>=4.40.0",
    "clip-by-openai",
    "sentence-transformers>=2.2.0",
    
    # Face analysis and emotion recognition
    "deepface>=0.0.91",
    "retinaface>=0.0.17",
    "mediapipe>=0.10.0",
    "face-recognition>=1.3.0",
    "fer>=22.5.0",
    "insightface>=0.7.3",
    
    # OpenFace 3.0 dependencies
    "dlib>=19.24.0",
    "imutils>=0.5.4",
    "cmake>=3.22.0",
    
    # Additional ML/AI tools
    "openai>=1.0.0",
    "huggingface-hub>=0.20.0",
    "accelerate>=0.20.0",
    "datasets>=2.16.0",
    "langchain>=0.1.0",
    "langchain-openai>=0.1.0",
    
    # Data processing and visualization
    "seaborn>=0.12.0",
    "plotly>=5.17.0",
    "scipy>=1.11.0",
    "scikit-learn>=1.3.0",
    "networkx>=3.1",
    "pydantic>=2.0.0",
    "typer>=0.9.0",
    
    # Additional video processing
    "imageio>=2.31.0",
    "imageio-ffmpeg>=0.4.8",
    "av>=10.0.0",
    
    # Multimodal and advanced AI
    "open-clip-torch>=2.24.0",
    "clip-interrogator>=0.6.0",
    
    # Database and storage
    "sqlalchemy>=2.0.0",
    "alembic>=1.12.0",
    
    # Configuration and utilities
    "pyyaml>=6.0",
    "rich>=13.0.0",
    "click>=8.0.0",
]

[project.optional-dependencies]
dev = [
    "black>=23.0.0",
    "flake8>=6.0.0",
    "pre-commit>=3.0.0",
    "jupyter>=1.0.0",
    "jupyterlab>=4.0.0",
    "pytest-cov>=4.0.0",
    "mypy>=1.5.0",
]
annotation = [
    "label-studio-sdk>=0.0.32",
    "fiftyone>=0.23.0",
    "roboflow>=1.1.0",
]
all = [
    "videoannotator[dev,annotation]"
]

[project.urls]
Homepage = "https://github.com/your-org/VideoAnnotator"
Documentation = "https://github.com/your-org/VideoAnnotator/wiki"
Repository = "https://github.com/your-org/VideoAnnotator"
Issues = "https://github.com/your-org/VideoAnnotator/issues"

[project.scripts]
videoannotator = "main:main"

[tool.setuptools.packages.find]
where = ["src"]
include = ["src*"]

[tool.setuptools.package-data]
"*" = ["*.yaml", "*.yml", "*.json", "*.md"]

[tool.black]
line-length = 88
target-version = ['py38']
include = '\.pyi?$'
extend-exclude = '''
/(
  # directories
  \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | build
  | dist
)/
'''

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = ["test_*.py", "*_test.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]
addopts = [
    "--strict-markers",
    "--strict-config",
    "--verbose",
    "--tb=short",
    "--cov=src",
    "--cov-report=term-missing",
    "--cov-report=html",
    "--cov-report=xml",
]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "unit: marks tests as unit tests",
    "performance: marks tests as performance tests",
]

[tool.mypy]
python_version = "3.8"
check_untyped_defs = true
disallow_any_generics = true
disallow_incomplete_defs = true
disallow_untyped_defs = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_return_any = true
warn_unreachable = true
strict_equality = true

[[tool.mypy.overrides]]
module = [
    "cv2",
    "whisper", 
    "pyannote.*",
    "ultralytics",
    "clip",
    "deepface",
    "mediapipe",
    "librosa",
    "moviepy.*",
    "scenedetect.*",
    "transformers",
    "torch",
    "torchvision",
    "torchaudio",
    "supervision",
    "timm",
    "sentence_transformers",
    "retinaface",
    "face_recognition",
    "fer",
    "insightface",
    "dlib",
    "imutils",
    "speechbrain",
    "datasets",
    "langchain.*",
    "openai",
    "huggingface_hub",
    "accelerate",
    "plotly.*",
    "seaborn",
    "networkx",
    "label_studio_sdk",
    "fiftyone",
    "roboflow",
    "imageio",
    "av",
    "open_clip_torch",
    "clip_interrogator",
    "sqlalchemy",
    "alembic",
]
ignore_missing_imports = true

[tool.flake8]
max-line-length = 88
extend-ignore = ["E203", "W503"]
exclude = [
    ".git",
    "__pycache__",
    "build",
    "dist",
    ".venv",
    ".tox",
    ".eggs",
    "*.egg",
]
