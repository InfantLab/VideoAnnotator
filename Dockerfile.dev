# VideoAnnotator Development Docker Image - Simple Approach
# This image includes GPU support AND your local model cache for instant testing
# Copies your existing models/ and weights/ directories
#
# Usage:
#   docker build -f dockerfile.dev -t videoannotator:dev .
#   docker run --gpus all --rm -p 8000:8000 -v ${PWD}/data:/app/data videoannotator:dev

FROM nvidia/cuda:12.1.1-runtime-ubuntu22.04

# Use bash with pipefail so RUN commands that use a pipe fail when any stage does
SHELL ["/bin/bash","-o","pipefail","-lc"]

# Install base packages and locales in a single RUN to reduce image layers and
# avoid pulling recommended packages unnecessarily (DL3015, DL3059)
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl python3 python3-venv python3-pip git git-lfs ffmpeg \
    libgl1-mesa-dri libglib2.0-0 libsm6 libxext6 libxrender1 libgomp1 locales \
    && locale-gen en_US.UTF-8 \
    && update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8 \
    && rm -rf /var/lib/apt/lists/*

# Export UTF-8 locale for all processes
ENV LANG=en_US.UTF-8
ENV LC_ALL=en_US.UTF-8

# Initialize Git LFS, install uv and set PATH, copy project files, and install
# dependencies in grouped RUNs to reduce layers. The uv installer is a piped
# command; using SHELL with pipefail above ensures failures are detected (DL4006).
RUN git lfs install \
    && curl -LsSf https://astral.sh/uv/install.sh | sh \
    && export PATH="/root/.local/bin:${PATH}" \
    && mkdir -p /app

ENV PATH="/root/.local/bin:${PATH}"

WORKDIR /app

# Copy source code (excluding models via .dockerignore)
COPY . .

# Copy your local models and weights (the reliable approach)
# These should contain exactly what your pipelines need
COPY models/ /app/models/
COPY weights/ /app/weights/

# Install dependencies (excluding torch to avoid conflicts), install CUDA PyTorch
# and the specify-cli tool in one RUN to reduce layers (addresses DL3059)
RUN uv sync --frozen --no-editable \
    && uv pip install "torch==2.3.1+cu121" "torchvision==0.18.1+cu121" "torchaudio==2.3.1+cu121" --index-url https://download.pytorch.org/whl/cu121 \
    && uv tool install specify-cli --from git+https://github.com/github/spec-kit.git

# Verify GPU access and model cache (no model downloading needed!)
RUN uv run python3 -c "\
    import torch; \
    from pathlib import Path; \
    print(f'[DEV BUILD] CUDA available: {torch.cuda.is_available()}'); \
    models_count = len(list(Path('/app/models').rglob('*'))) if Path('/app/models').exists() else 0; \
    weights_count = len(list(Path('/app/weights').rglob('*'))) if Path('/app/weights').exists() else 0; \
    print(f'[DEV BUILD] Models directory: {models_count} files'); \
    print(f'[DEV BUILD] Weights directory: {weights_count} files'); \
    print('[DEV BUILD] Development image ready with local model cache!');"

# Set environment for development
ENV PYTHONUNBUFFERED=1
ENV CUDA_VISIBLE_DEVICES=0

# Create directories for mounted volumes
RUN mkdir -p /app/data /app/output /app/logs

EXPOSE 18011

CMD ["uv", "run", "python3", "api_server.py", "--log-level", "info", "--port", "18011"]
