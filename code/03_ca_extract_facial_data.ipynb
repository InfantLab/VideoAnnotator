{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Extract facial data from videos.\n",
    "\n",
    "We use a range of libraries to extract facial data from the videos. The main library is [DeepFace](https://github.com/serengil/deepface) but we also considered FER - [Facial Expression Recognition](https://github.com/justinshenk/fer).\n",
    "\n",
    "DeepFace is a framework that wraps several popular face recognition models, accessible as a single API. These backends are \n",
    "\n",
    "backends = [ 'opencv', 'retinaface', 'mtcnn', 'ssd', 'dlib', 'mediapipe', 'yolov8', 'centerface']\n",
    "\n",
    "For demographics (age, gender,race and emotion), it's unclear how many backends are available or if deepface has its own models. But performance can depend upon the recognition dmodel used. \n",
    "\n",
    "\n",
    "`pip install deepface`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 DeepFace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepface import DeepFace\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "project_root = os.path.join(\"..\")\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from src.processors.face_processor import extract_faces_from_video, get_facial_stats\n",
    "from src.utils.io_utils import getProcessedVideos, saveProcessedVideos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get paths for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add these to your imports\n",
    "from src.config import PATH_CONFIG\n",
    "from src.utils.notebook_utils import display_config_info, ensure_dir_exists\n",
    "\n",
    "# Get paths from config\n",
    "videos_in = PATH_CONFIG['videos_in']\n",
    "data_out = PATH_CONFIG['data_out']\n",
    "\n",
    "# Ensure output directory exists\n",
    "if ensure_dir_exists(data_out):\n",
    "    print(f\"Created output directory: {data_out}\")\n",
    "\n",
    "# Display configuration information\n",
    "display_config_info(videos_in, data_out, \"Processing Configuration\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different face detection models built into deepface\n",
    "detector_backends = [ 'opencv', 'retinaface', 'mtcnn', 'ssd', 'dlib', 'mediapipe', 'yolov8', 'centerface']\n",
    "backends = [\n",
    "  'opencv', \n",
    "  'ssd', \n",
    "  'dlib', \n",
    "  'mtcnn', \n",
    "  'retinaface', \n",
    "  'mediapipe',\n",
    "  'yolov8',\n",
    "  'yunet',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedvideos = getProcessedVideos(data_out)\n",
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method A: Process All Videos at Once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to track Method A processing if it doesn't exist\n",
    "from src.processors.face_processor import process_video_faces\n",
    "\n",
    "\n",
    "if \"Face_Processing_Complete\" not in processedvideos.columns:\n",
    "    processedvideos[\"Face_Processing_Complete\"] = False\n",
    "\n",
    "# Parameters\n",
    "force_process = True  # Set to True to reprocess already processed videos\n",
    "backend = \"retinaface\"        # Face detection backend to use\n",
    "skip_frames = 0        # Process every frame (set higher to skip frames)\n",
    "\n",
    "# Process each video\n",
    "for index, row in processedvideos.iterrows():\n",
    "    if force_process or pd.isnull(row.get(\"Face_Processing_Complete\")) or not row.get(\"Face_Processing_Complete\"):\n",
    "        video_path = os.path.join(videos_in, row[\"VideoID\"])\n",
    "        \n",
    "        # Get video metadata for normalization\n",
    "        video_metadata = {\n",
    "            \"Height\": row[\"Height\"], \n",
    "            \"Width\": row[\"Width\"]\n",
    "        }\n",
    "        \n",
    "        # Load pose data if available for matching\n",
    "        # TODO - maybe make this wrok later.\n",
    "        poses_df = None\n",
    "        # if not pd.isnull(row.get(\"Keypoints.file\")) and os.path.exists(row[\"Keypoints.file\"]):\n",
    "        #     try:\n",
    "        #         poses_df = pd.read_csv(row[\"Keypoints.file\"])\n",
    "        #         print(f\"Loaded pose data for {row['VideoID']} with {len(poses_df)} records\")\n",
    "        #     except Exception as e:\n",
    "        #         print(f\"Error loading pose data: {e}\")\n",
    "        \n",
    "        # Process the video with all steps\n",
    "        print(f\"Processing {row['VideoID']} using Method A...\")\n",
    "        try:\n",
    "            results = process_video_faces(\n",
    "                video_path=video_path,\n",
    "                output_dir=data_out,\n",
    "                video_metadata=video_metadata,\n",
    "                poses_df=poses_df,\n",
    "                skip_frames=skip_frames,\n",
    "                backend=backend,\n",
    "                force_process=force_process\n",
    "            )\n",
    "            \n",
    "            # Update the dataframe with results\n",
    "            if results[\"faces\"]:\n",
    "                processedvideos.at[index, \"Faces.file\"] = results[\"faces\"]\n",
    "                processedvideos.at[index, \"Faces.when\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
    "            \n",
    "            if results[\"normed\"]:\n",
    "                processedvideos.at[index, \"Faces.normed\"] = results[\"normed\"]\n",
    "                \n",
    "            if results[\"matched\"]:\n",
    "                processedvideos.at[index, \"Faces.matched\"] = results[\"matched\"]\n",
    "                \n",
    "            processedvideos.at[index, \"Face_Processing_Complete\"] = True\n",
    "            print(f\"✅ Completed processing for {row['VideoID']}\")\n",
    "        \n",
    "            # Save updated processedvideos\n",
    "            saveProcessedVideos(processedvideos, data_out)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {row['VideoID']}: {e}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"Already processed {row['VideoID']} (skipping)\")\n",
    "\n",
    "\n",
    "\n",
    "# Display updated dataframe\n",
    "processedvideos[[\"VideoID\", \"Faces.file\", \"Faces.normed\", \"Face_Processing_Complete\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## METHOD B - Step by step\n",
    "\n",
    "## First Detect faces and save info to csv (emotion, gender, age, race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each video and extract facial features\n",
    "forceProcess = False\n",
    "backend = \"retinaface\"  # Change to the desired backend\n",
    "features = ['emotion','age','gender']\n",
    "\n",
    "for index, row in processedvideos.iterrows():\n",
    "    if forceProcess or pd.isnull(row.get(\"Face_Processing_Complete\")) or not row.get(\"Face_Processing_Complete\"):\n",
    "        video_path = os.path.join(videos_in, row[\"VideoID\"])\n",
    "        video_name = os.path.basename(video_path)\n",
    "        base_name = os.path.splitext(video_name)[0]\n",
    "        faces_path = os.path.join(data_out, f\"{base_name}_faces_{backend}.csv\")\n",
    "        \n",
    "        # Get video metadata for normalization\n",
    "        video_metadata = {\n",
    "            \"Height\": row[\"Height\"], \n",
    "            \"Width\": row[\"Width\"]\n",
    "        }\n",
    "        \n",
    "        # Process the video with DeepFace\n",
    "        print(f\"Processing {row['VideoID']} using DeepFace...\")\n",
    "        try:\n",
    "            results = extract_faces_from_video(\n",
    "                video_path=video_path,\n",
    "                output_file=faces_path,\n",
    "                backend = backend,\n",
    "                skip_frames=0,\n",
    "                features = features\n",
    "            )            \n",
    "            # Update the dataframe with results\n",
    "            if results[\"faces\"]:\n",
    "                processedvideos.at[index, \"Faces.file\"] = results[\"faces\"]\n",
    "                processedvideos.at[index, \"Faces.when\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
    "                            \n",
    "            processedvideos.at[index, \"Face_Processing_Complete\"] = True\n",
    "            print(f\"✅ Completed processing for {row['VideoID']}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {row['VideoID']}: {str(e)}\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"Already processed {row['VideoID']} (skipping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Match face detection with pose detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Faces.matched column to processedvideos if it doesn't exist\n",
    "if \"Faces.matched\" not in processedvideos.columns:\n",
    "    processedvideos[\"Faces.matched\"] = None\n",
    "\n",
    "# Process each video to match faces with poses\n",
    "forceProcess = False\n",
    "\n",
    "for index, row in processedvideos.iterrows():\n",
    "    if (forceProcess or pd.isnull(row[\"Faces.matched\"])) and not pd.isnull(row[\"Faces.file\"]) \\\n",
    "       and not pd.isnull(row[\"Keypoints.file\"]):\n",
    "        try:\n",
    "            # Load faces and keypoints dataframes\n",
    "            faces_df = pd.read_csv(row[\"Faces.file\"])\n",
    "            poses_df = pd.read_csv(row[\"Keypoints.file\"])\n",
    "            \n",
    "            # Match faces to poses\n",
    "            matched_df = match_faces_to_poses(faces_df, poses_df)\n",
    "            \n",
    "            # Save matched data\n",
    "            stemname = os.path.splitext(row[\"Faces.file\"])[0]\n",
    "            matched_path = f\"{stemname}_matched.csv\"\n",
    "            matched_df.to_csv(matched_path, index=False)\n",
    "            \n",
    "            # Update record\n",
    "            processedvideos.at[index, \"Faces.matched\"] = matched_path\n",
    "            print(f\"Matched faces to poses for {row['VideoID']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error matching faces for {row['VideoID']}: {e}\")\n",
    "    elif not pd.isnull(row[\"Faces.matched\"]):\n",
    "        print(f\"Already matched faces for {row['VideoID']}\")\n",
    "        \n",
    "saveProcessedVideos(processedvideos, data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize facial coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_facial_keypoints(faces_df, height, width):\n",
    "    \"\"\"\n",
    "    Normalize facial keypoint coordinates by dividing by video dimensions.\n",
    "    \n",
    "    Args:\n",
    "        faces_df (DataFrame): DataFrame with facial keypoints\n",
    "        height (int): Video height\n",
    "        width (int): Video width\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame: DataFrame with normalized coordinates\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    normed_df = faces_df.copy()\n",
    "    \n",
    "    # Get the x and y column names for facial landmarks\n",
    "    facecolsx, facecolsy = utils.getfacecols()\n",
    "    \n",
    "    # Normalize x coordinates by dividing by width\n",
    "    for col in facecolsx:\n",
    "        if col in normed_df.columns:\n",
    "            normed_df[col] = normed_df[col] / width\n",
    "    \n",
    "    # Normalize y coordinates by dividing by height\n",
    "    for col in facecolsy:\n",
    "        if col in normed_df.columns:\n",
    "            normed_df[col] = normed_df[col] / height\n",
    "    \n",
    "    return normed_df\n",
    "\n",
    "# Process each video to normalize facial coordinates\n",
    "forceNormalize = False\n",
    "\n",
    "for index, row in processedvideos.iterrows():\n",
    "    if (forceNormalize or pd.isnull(row.get(\"Faces.normed\"))) and not pd.isnull(row[\"Faces.file\"]):\n",
    "        try:\n",
    "            # Load faces dataframe\n",
    "            faces_df = pd.read_csv(row[\"Faces.file\"])\n",
    "            \n",
    "            # Normalize coordinates\n",
    "            normed_df = normalize_facial_keypoints(faces_df, row[\"Height\"], row[\"Width\"])\n",
    "            \n",
    "            # Save normalized data\n",
    "            stemname = os.path.splitext(row[\"Faces.file\"])[0]\n",
    "            normed_path = f\"{stemname}_normed.csv\"\n",
    "            normed_df.to_csv(normed_path, index=False)\n",
    "            \n",
    "            # Update record\n",
    "            processedvideos.at[index, \"Faces.normed\"] = normed_path\n",
    "            print(f\"Normalized facial data for {row['VideoID']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error normalizing faces for {row['VideoID']}: {e}\")\n",
    "    elif not pd.isnull(row.get(\"Faces.normed\")):\n",
    "        print(f\"Already normalized faces for {row['VideoID']}\")\n",
    "\n",
    "utils.saveProcessedVideos(processedvideos, data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Facial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a cell to generate statistics and visualize facial data\n",
    "for index, row in processedvideos.iterrows():\n",
    "    if not pd.isnull(row[\"Faces.file\"]) and os.path.exists(row[\"Faces.file\"]):\n",
    "        try:\n",
    "            # Load faces dataframe\n",
    "            faces_df = pd.read_csv(row[\"Faces.file\"])\n",
    "            \n",
    "            # Get statistics\n",
    "            stats = get_facial_stats(faces_df)\n",
    "            print(f\"\\nFacial Stats for {row['VideoID']}:\")\n",
    "            print(f\"Total faces detected: {stats['total_faces']}\")\n",
    "            print(f\"Frames with faces: {stats['unique_frames']}\")\n",
    "            print(f\"Average faces per frame: {stats['avg_faces_per_frame']:.2f}\")\n",
    "            \n",
    "            # Display emotion distribution\n",
    "            if 'emotion_distribution' in stats:\n",
    "                print(\"\\nEmotion distribution:\")\n",
    "                emotions = stats['emotion_distribution']\n",
    "                for emotion, value in emotions.items():\n",
    "                    print(f\"  {emotion}: {value:.2f}\")\n",
    "                    \n",
    "                # Plot emotions\n",
    "                plt.figure(figsize=(10, 5))\n",
    "                plt.bar(emotions.keys(), emotions.values())\n",
    "                plt.title(f\"Emotion Distribution for {row['VideoID']}\")\n",
    "                plt.ylabel(\"Average Score\")\n",
    "                plt.xticks(rotation=45)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "            print(\"-\" * 50)\n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing facial data for {row['VideoID']}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyjokes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
