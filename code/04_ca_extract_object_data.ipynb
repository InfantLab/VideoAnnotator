{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4 Extract object data\n",
                "\n",
                "Using YOLOv8 for object detection to track objects in the videos. This will help identify toys and props used in baby joke interactions.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import math\n",
                "import sys\n",
                "import time\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import cv2\n",
                "import torch\n",
                "from ultralytics import YOLO\n",
                "\n",
                "import sys\n",
                "\n",
                "project_root = os.path.join(\"..\")\n",
                "sys.path.append(project_root)\n",
                "\n",
                "from src.processors.face_processor import extract_faces_from_video, get_facial_stats\n",
                "from src.utils.io_utils import getProcessedVideos, saveProcessedVideos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add these to your imports\n",
                "from src.config import PATH_CONFIG\n",
                "from src.utils.notebook_utils import display_config_info, ensure_dir_exists\n",
                "\n",
                "# Get paths from config\n",
                "videos_in = PATH_CONFIG['videos_in']\n",
                "data_out = PATH_CONFIG['data_out']\n",
                "\n",
                "# Ensure output directory exists\n",
                "if ensure_dir_exists(data_out):\n",
                "    print(f\"Created output directory: {data_out}\")\n",
                "\n",
                "# Display configuration information\n",
                "display_config_info(videos_in, data_out, \"Processing Configuration\")\n",
                "\n",
                "processedvideos = getProcessedVideos(data_out)\n",
                "processedvideos.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load YOLOv8 model for object detection\n",
                "object_model = YOLO('yolov8n.pt')  # Uses the nano model for object detection\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add Objects columns to processedvideos if they don't exist\n",
                "from src.processors.object_processor import extract_objects_from_video, match_objects_to_persons, normalize_object_coordinates\n",
                "\n",
                "\n",
                "if \"Objects.file\" not in processedvideos.columns:\n",
                "    processedvideos[\"Objects.file\"] = None\n",
                "if \"Objects.when\" not in processedvideos.columns:\n",
                "    processedvideos[\"Objects.when\"] = None\n",
                "if \"Objects.normed\" not in processedvideos.columns:\n",
                "    processedvideos[\"Objects.normed\"] = None\n",
                "if \"Objects.matched\" not in processedvideos.columns:\n",
                "    processedvideos[\"Objects.matched\"] = None\n",
                "\n",
                "# Process each video for object detection\n",
                "force_process = False\n",
                "\n",
                "for index, row in processedvideos.iterrows():\n",
                "    #testing only on first 5 videos\n",
                "    if index > 5:\n",
                "        break\n",
                "    if force_process or pd.isnull(row[\"Objects.file\"]):\n",
                "        try:\n",
                "            # Get video path\n",
                "            video_path = os.path.join(videos_in, row[\"VideoID\"])\n",
                "            \n",
                "            # Extract objects\n",
                "            objects_df = extract_objects_from_video(video_path, object_model)\n",
                "            \n",
                "            # Save objects data\n",
                "            stemname = os.path.splitext(row[\"VideoID\"])[0]\n",
                "            objects_path = os.path.join(data_out, f\"{stemname}.objects.csv\")\n",
                "            objects_df.to_csv(objects_path, index=False)\n",
                "            \n",
                "            # Update record\n",
                "            processedvideos.at[index, \"Objects.file\"] = objects_path\n",
                "            processedvideos.at[index, \"Objects.when\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
                "            \n",
                "            # Normalize coordinates\n",
                "            if len(objects_df) > 0:\n",
                "                normed_df = normalize_object_coordinates(objects_df, row[\"Height\"], row[\"Width\"])\n",
                "                normed_path = os.path.join(data_out, f\"{stemname}.objects_normed.csv\")\n",
                "                normed_df.to_csv(normed_path, index=False)\n",
                "                processedvideos.at[index, \"Objects.normed\"] = normed_path\n",
                "            \n",
                "            # Match objects to persons if keypoints exist\n",
                "            if not pd.isnull(row[\"Keypoints.normed\"]) and len(objects_df) > 0:\n",
                "                poses_df = pd.read_csv(row[\"Keypoints.normed\"])\n",
                "                matched_df = match_objects_to_persons(normed_df, poses_df)\n",
                "                matched_path = os.path.join(data_out, f\"{stemname}.objects_matched.csv\")\n",
                "                matched_df.to_csv(matched_path, index=False)\n",
                "                processedvideos.at[index, \"Objects.matched\"] = matched_path\n",
                "            \n",
                "            print(f\"Processed objects for {row['VideoID']}\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error processing objects for {row['VideoID']}: {e}\")\n",
                "    else:\n",
                "        print(f\"Already processed objects for {row['VideoID']}\")\n",
                "\n",
                "saveProcessedVideos(processedvideos, data_out)\n",
                "processedvideos[['VideoID', 'Objects.file', 'Objects.normed', 'Objects.matched']].head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "babyjokes",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
