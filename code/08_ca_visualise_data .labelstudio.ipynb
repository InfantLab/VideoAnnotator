{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 Reviewing videoannotations in Label Studio\n",
    "\n",
    "[Label Studio](https://labelstud.io/) is a tool for creating training data for machine learning. It is browser based and can be used to annotate video, images and other data. \n",
    "\n",
    "We will use it to review the annotations we made in the previous steps. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python-dotenv could not parse statement starting at line 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import utils\n",
    "import calcs\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing processedvideos.xlsx with 54 rows.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VideoID</th>\n",
       "      <th>ChildID</th>\n",
       "      <th>JokeType</th>\n",
       "      <th>Joke.Label</th>\n",
       "      <th>JokeNum</th>\n",
       "      <th>JokeRep</th>\n",
       "      <th>JokeTake</th>\n",
       "      <th>HowFunny</th>\n",
       "      <th>LaughYesNo</th>\n",
       "      <th>Frames</th>\n",
       "      <th>...</th>\n",
       "      <th>Objects.file</th>\n",
       "      <th>Objects.when</th>\n",
       "      <th>Understand.file</th>\n",
       "      <th>Understand.when</th>\n",
       "      <th>Faces.normed</th>\n",
       "      <th>Keypoints.normed</th>\n",
       "      <th>annotatedVideo</th>\n",
       "      <th>annotated.when</th>\n",
       "      <th>Diary.file</th>\n",
       "      <th>Diary.when</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2UWdXP.joke1.rep2.take1.Peekaboo.mp4</td>\n",
       "      <td>2UWdXP</td>\n",
       "      <td>Peekaboo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Slightly funny</td>\n",
       "      <td>No</td>\n",
       "      <td>217</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke1.rep2.take1.Peek...</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke1.rep2.take1.Peek...</td>\n",
       "      <td>../data/2_final/2UWdXP.joke1.rep2.take1.Peekab...</td>\n",
       "      <td>2024-02-16 11:03:50</td>\n",
       "      <td>..\\data\\1_interim\\2UWdXP.joke1.rep2.take1.Peek...</td>\n",
       "      <td>2024-09-11 10:13:58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2UWdXP.joke1.rep3.take1.Peekaboo.mp4</td>\n",
       "      <td>2UWdXP</td>\n",
       "      <td>Peekaboo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Slightly funny</td>\n",
       "      <td>No</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke1.rep3.take1.Peek...</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke1.rep3.take1.Peek...</td>\n",
       "      <td>../data/2_final/2UWdXP.joke1.rep3.take1.Peekab...</td>\n",
       "      <td>2024-02-16 11:03:51</td>\n",
       "      <td>..\\data\\1_interim\\2UWdXP.joke1.rep3.take1.Peek...</td>\n",
       "      <td>2024-09-11 10:13:59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2UWdXP.joke2.rep1.take1.NomNomNom.mp4</td>\n",
       "      <td>2UWdXP</td>\n",
       "      <td>NomNomNom</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Funny</td>\n",
       "      <td>No</td>\n",
       "      <td>95</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke2.rep1.take1.NomN...</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke2.rep1.take1.NomN...</td>\n",
       "      <td>../data/2_final/2UWdXP.joke2.rep1.take1.NomNom...</td>\n",
       "      <td>2024-02-16 11:03:52</td>\n",
       "      <td>..\\data\\1_interim\\2UWdXP.joke2.rep1.take1.NomN...</td>\n",
       "      <td>2024-09-11 10:14:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2UWdXP.joke2.rep2.take1.NomNomNom.mp4</td>\n",
       "      <td>2UWdXP</td>\n",
       "      <td>NomNomNom</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Slightly funny</td>\n",
       "      <td>No</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke2.rep2.take1.NomN...</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke2.rep2.take1.NomN...</td>\n",
       "      <td>../data/2_final/2UWdXP.joke2.rep2.take1.NomNom...</td>\n",
       "      <td>2024-02-16 11:03:53</td>\n",
       "      <td>..\\data\\1_interim\\2UWdXP.joke2.rep2.take1.NomN...</td>\n",
       "      <td>2024-09-11 10:14:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2UWdXP.joke2.rep3.take1.NomNomNom.mp4</td>\n",
       "      <td>2UWdXP</td>\n",
       "      <td>NomNomNom</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Slightly funny</td>\n",
       "      <td>No</td>\n",
       "      <td>133</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke2.rep3.take1.NomN...</td>\n",
       "      <td>../data/1_interim/2UWdXP.joke2.rep3.take1.NomN...</td>\n",
       "      <td>../data/2_final/2UWdXP.joke2.rep3.take1.NomNom...</td>\n",
       "      <td>2024-02-16 11:03:54</td>\n",
       "      <td>..\\data\\1_interim\\2UWdXP.joke2.rep3.take1.NomN...</td>\n",
       "      <td>2024-09-11 10:14:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 VideoID ChildID   JokeType  Joke.Label  \\\n",
       "0   2UWdXP.joke1.rep2.take1.Peekaboo.mp4  2UWdXP   Peekaboo           2   \n",
       "1   2UWdXP.joke1.rep3.take1.Peekaboo.mp4  2UWdXP   Peekaboo           2   \n",
       "2  2UWdXP.joke2.rep1.take1.NomNomNom.mp4  2UWdXP  NomNomNom           1   \n",
       "3  2UWdXP.joke2.rep2.take1.NomNomNom.mp4  2UWdXP  NomNomNom           1   \n",
       "4  2UWdXP.joke2.rep3.take1.NomNomNom.mp4  2UWdXP  NomNomNom           1   \n",
       "\n",
       "   JokeNum  JokeRep  JokeTake        HowFunny LaughYesNo  Frames  ...  \\\n",
       "0        1        2         1  Slightly funny         No     217  ...   \n",
       "1        1        3         1  Slightly funny         No     152  ...   \n",
       "2        2        1         1           Funny         No      95  ...   \n",
       "3        2        2         1  Slightly funny         No      97  ...   \n",
       "4        2        3         1  Slightly funny         No     133  ...   \n",
       "\n",
       "   Objects.file  Objects.when  Understand.file  Understand.when  \\\n",
       "0           NaN           NaN              NaN              NaN   \n",
       "1           NaN           NaN              NaN              NaN   \n",
       "2           NaN           NaN              NaN              NaN   \n",
       "3           NaN           NaN              NaN              NaN   \n",
       "4           NaN           NaN              NaN              NaN   \n",
       "\n",
       "                                        Faces.normed  \\\n",
       "0  ../data/1_interim/2UWdXP.joke1.rep2.take1.Peek...   \n",
       "1  ../data/1_interim/2UWdXP.joke1.rep3.take1.Peek...   \n",
       "2  ../data/1_interim/2UWdXP.joke2.rep1.take1.NomN...   \n",
       "3  ../data/1_interim/2UWdXP.joke2.rep2.take1.NomN...   \n",
       "4  ../data/1_interim/2UWdXP.joke2.rep3.take1.NomN...   \n",
       "\n",
       "                                    Keypoints.normed  \\\n",
       "0  ../data/1_interim/2UWdXP.joke1.rep2.take1.Peek...   \n",
       "1  ../data/1_interim/2UWdXP.joke1.rep3.take1.Peek...   \n",
       "2  ../data/1_interim/2UWdXP.joke2.rep1.take1.NomN...   \n",
       "3  ../data/1_interim/2UWdXP.joke2.rep2.take1.NomN...   \n",
       "4  ../data/1_interim/2UWdXP.joke2.rep3.take1.NomN...   \n",
       "\n",
       "                                      annotatedVideo       annotated.when  \\\n",
       "0  ../data/2_final/2UWdXP.joke1.rep2.take1.Peekab...  2024-02-16 11:03:50   \n",
       "1  ../data/2_final/2UWdXP.joke1.rep3.take1.Peekab...  2024-02-16 11:03:51   \n",
       "2  ../data/2_final/2UWdXP.joke2.rep1.take1.NomNom...  2024-02-16 11:03:52   \n",
       "3  ../data/2_final/2UWdXP.joke2.rep2.take1.NomNom...  2024-02-16 11:03:53   \n",
       "4  ../data/2_final/2UWdXP.joke2.rep3.take1.NomNom...  2024-02-16 11:03:54   \n",
       "\n",
       "                                          Diary.file           Diary.when  \n",
       "0  ..\\data\\1_interim\\2UWdXP.joke1.rep2.take1.Peek...  2024-09-11 10:13:58  \n",
       "1  ..\\data\\1_interim\\2UWdXP.joke1.rep3.take1.Peek...  2024-09-11 10:13:59  \n",
       "2  ..\\data\\1_interim\\2UWdXP.joke2.rep1.take1.NomN...  2024-09-11 10:14:00  \n",
       "3  ..\\data\\1_interim\\2UWdXP.joke2.rep2.take1.NomN...  2024-09-11 10:14:01  \n",
       "4  ..\\data\\1_interim\\2UWdXP.joke2.rep3.take1.NomN...  2024-09-11 10:14:02  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videos_in = os.path.join(\"..\",\"LookitLaughter.test\")\n",
    "demo_data = os.path.join(\"..\",\"data\", \"demo\")\n",
    "temp_out = os.path.join(\"..\",\"data\",\"0_temp\")\n",
    "data_out = os.path.join(\"..\",\"data\",\"1_interim\")\n",
    "videos_out = os.path.join(\"..\",\"data\",\"2_final\")\n",
    "\n",
    "metadata_file = \"_LookitLaughter.xlsx\"\n",
    "\n",
    "processedvideos = utils.getProcessedVideos(data_out)\n",
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a couple of files for testing\n",
    "VIDEO_FILE  = os.path.join(videos_in, \"2UWdXP.joke1.rep2.take1.Peekaboo.mp4\")\n",
    "VIDEO_FILE2 = os.path.join(videos_in, \"2UWdXP.joke2.rep1.take1.NomNomNom.mp4\")\n",
    "AUDIO_FILE = os.path.join(data_out, \"2UWdXP.joke1.rep2.take1.Peekaboo.wav\")\n",
    "SPEECH_FILE = os.path.join(data_out, \"2UWdXP.joke1.rep2.take1.Peekaboo.json\")\n",
    "\n",
    "testset = [VIDEO_FILE, VIDEO_FILE2] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Launch Label Studio\n",
    "\n",
    "Let's build the command to launch Label Studio inside a docker container.\n",
    "Getting the folder paths correct is a bit tricky. There is some guidance here - [Label Studio Documentation — Start commands for Label Studio](https://labelstud.io/guide/start#Run_Label_Studio_on_Docker_and_use_local_storage)\n",
    "\n",
    "THis is how i set it up.\n",
    "\n",
    "$PWD = C:/Users/caspar/OneDrive\n",
    "OneDrive/ls/data/\n",
    "OneDrive/ls/files/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'docker run -it -p 8080:8080 -e LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true -e LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/label-studio -v $PWD/ls/data:/label-studio/data -v $PWD/ls/files:/label-studio/files heartexlabs/label-studio:latest label-studio' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Use shell=True for Windows and pass the command as a string\u001b[39;00m\n\u001b[0;32m     12\u001b[0m command_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(command)\n\u001b[1;32m---> 13\u001b[0m result \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun(command_str, check\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, shell\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, capture_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\caspar\\Anaconda3\\envs\\babyjokes\\Lib\\subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[1;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[0;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[1;31mCalledProcessError\u001b[0m: Command 'docker run -it -p 8080:8080 -e LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true -e LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/label-studio -v $PWD/ls/data:/label-studio/data -v $PWD/ls/files:/label-studio/files heartexlabs/label-studio:latest label-studio' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "#Let's build a Power Shell command to launch Label Studio inside a docker container.\n",
    "command = [\n",
    "    'docker run -it',\n",
    "    '-p', \"8080:8080\", #port it runs on\n",
    "    '-e', \"LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true\",  #necessary environment variables\n",
    "    '-e', \"LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/label-studio\",\n",
    "    '-v', \"$PWD/ls/data:/label-studio/data\", #data volume location and mount point\n",
    "    '-v', \"$PWD/ls/files:/label-studio/files\", #files volume location and mount point\n",
    "    'heartexlabs/label-studio:latest', 'label-studio' #docker image to use\n",
    "]\n",
    "# Use shell=True for Windows and pass the command as a string\n",
    "command_str = ' '.join(command)\n",
    "result = subprocess.run(command_str, check=True, shell=True, capture_output=True, text=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docker run -it -p 8080:8080 -e LABEL_STUDIO_LOCAL_FILES_SERVING_ENABLED=true -e LABEL_STUDIO_LOCAL_FILES_DOCUMENT_ROOT=/label-studio -v $PWD/ls/data:/label-studio/data -v $PWD/ls/files:/label-studio/files heartexlabs/label-studio:latest label-studio'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'label_studio'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01multralytics\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlabel_studio\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'label_studio'"
     ]
    }
   ],
   "source": [
    "# Define the URL where Label Studio is accessible and the API key for your user account\n",
    "LABEL_STUDIO_URL = 'http://localhost:8080'\n",
    "API_KEY = 'd6f8a2622d39e9d89ff0dfef1a80ad877f4ee9e3'\n",
    "\n",
    "# Import the SDK and the client module\n",
    "from label_studio_sdk.client import LabelStudio\n",
    "\n",
    "# Connect to the Label Studio API and check the connection\n",
    "ls = LabelStudio(base_url=LABEL_STUDIO_URL, api_key=API_KEY)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.1 Is dataset already created?\n",
    "\n",
    "FiftyOne may aleady have a dataset created. Let's check. And reload it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved datasets:  LookitLaughter.test\n"
     ]
    }
   ],
   "source": [
    "datasets = fo.list_datasets()\n",
    "if len(datasets) == 0:\n",
    "    print(\"No datasets found. Load in step 7.1.2\")\n",
    "else:\n",
    "    print(\"Loading saved datasets: \", datasets[0])\n",
    "    dataset = fo.load_dataset(datasets[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1.2 Populate a FiftyOne dataset with our videos and labels.\n",
    "\n",
    "Either there is no existing dataset or we want to rebuild it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Either  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo.delete_datasets(\"*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |███████████████████| 54/54 [26.6ms elapsed, 0s remaining, 2.0K samples/s]   \n",
      "Computing metadata...\n",
      " 100% |███████████████████| 54/54 [459.5ms elapsed, 0s remaining, 117.5 samples/s]     \n"
     ]
    }
   ],
   "source": [
    "# Create a dataset from a directory of videos\n",
    "dataset = fo.Dataset.from_videos_dir(\"../LookitLaughter.test\")\n",
    "dataset.ensure_frames()\n",
    "dataset.compute_metadata()\n",
    "\n",
    "dataset.name = 'LookitLaughter.test'\n",
    "\n",
    "\n",
    "dataset.add_sample_field(\"JokeType\", fo.StringField, description=\"What joke is being told?\")\n",
    "dataset.add_sample_field(\"HowFunny\", fo.StringField, description=\"How funny is the joke?\")\n",
    "dataset.add_sample_field(\"LaughYesNo\",  fo.BooleanField, description=\"Did the child laugh?\")\n",
    "dataset.add_sample_field(\"ChildSide\",  fo.IntField, description=\"Is the child on left (-1) or right (1) of adult or on lap (0)?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see if we can add our metadata classifications. Recalling that each video demos one joke type `[Peekaboo,TearingPaper,NomNomNom,ThatsNotAHat,ThatsNotACat]` and has rating of how funny the baby found it `[Not Funny, Slightly Funny, Funny, Extremely Funny]` and whether they laughed `[Yes, No]`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the joke type, how funny and laugh yes/no for each sample in the dataset\n",
    "for sample in dataset:\n",
    "    #split the filepath to get the video name, system independent\n",
    "    videoname = os.path.basename(sample.filepath)\n",
    "    phrase = processedvideos[processedvideos[\"VideoID\"]==videoname]\n",
    "    if len(phrase) == 0:\n",
    "        print(f\"Video {videoname} not found in processed videos.\")\n",
    "        continue\n",
    "    sample[\"VideoID\"]  = phrase[\"VideoID\"].values[0]\n",
    "    sample[\"JokeType\"]  = phrase[\"JokeType\"].values[0]\n",
    "    sample[\"HowFunny\"]  = phrase[\"HowFunny\"].values[0]\n",
    "    sample[\"LaughYesNo\"]  = (phrase[\"LaughYesNo\"].values[0] == \"Yes\")\n",
    "    sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idx2person(idx):\n",
    "    idx = int(idx)\n",
    "    if idx == 0:\n",
    "        return \"Child\"\n",
    "    elif idx == 1:\n",
    "        return \"Adult\"\n",
    "    else:\n",
    "        return \"Unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add the frame by frame annotations directly onto the videos inside fiftyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's start with people bounding boxes\n",
    "\n",
    "for sample in dataset:\n",
    "    #retrieve people bounding boxes from the keypoints file\n",
    "    keypoints = utils.readKeyPointsFromCSV(processedvideos,sample.filepath,normed= True)    \n",
    "\n",
    "    for framenumber, frame in sample.frames.items():\n",
    "        rows = keypoints[keypoints[\"frame\"]==framenumber -1] #framenumbver is 1 based in fiftyone!!\n",
    "        dets = []\n",
    "        for index, row in rows.iterrows():\n",
    "            person = idx2person(row[\"person\"])    \n",
    "            bbox = [row[\"bbox.x1\"], row[\"bbox.y1\"], row[\"bbox.x2\"], row[\"bbox.y2\"]]\n",
    "            bbox51 = calcs.xyxy2ltwh(bbox)\n",
    "            det = fo.Detection(label=person, bounding_box=bbox51)\n",
    "            dets.append(det)\n",
    "        frame[\"People\"] = fo.Detections(detections=dets)\n",
    "        sample.save()\n",
    "        \n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add the speech as temporal annotations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def framerange_from_timestamps(timestamps, fps, max_frames):\n",
    "    start = max(int(timestamps[0]*fps)+1 ,1)\n",
    "    end =  min(int(timestamps[1]*fps)+1, max_frames )\n",
    "    return start, end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.29889298892989\n",
      "We have a speech data file for 2UWdXP.joke1.rep2.take1.Peekaboo.mp4\n",
      "1 58\n",
      " Hey, excuse me. Look.\n",
      "58 101\n",
      " Ah, I can't handle this.\n",
      "101 129\n",
      " I'm just going to put it on.\n",
      "129 158\n",
      " You know, peek-a-boo!\n",
      "172 186\n",
      " Hey.\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "Only lists and tuples may be used in a list field",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 18\u001b[0m\n\u001b[0;32m     14\u001b[0m     phrases\u001b[38;5;241m.\u001b[39mappend(fo\u001b[38;5;241m.\u001b[39mTemporalDetection(label\u001b[38;5;241m=\u001b[39mphrase[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     15\u001b[0m                                     support\u001b[38;5;241m=\u001b[39m[start,end]))\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(phrase[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m---> 18\u001b[0m \u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSpeech\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m fo\u001b[38;5;241m.\u001b[39mTemporalDetections(detections\u001b[38;5;241m=\u001b[39mphrases)\n\u001b[0;32m     19\u001b[0m sample[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeech\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m phrases\n\u001b[0;32m     20\u001b[0m sample\u001b[38;5;241m.\u001b[39msave()\n",
      "File \u001b[1;32mc:\\Users\\caspar\\anaconda3\\envs\\babyjokes\\Lib\\site-packages\\fiftyone\\core\\sample.py:68\u001b[0m, in \u001b[0;36m_SampleMixin.__setitem__\u001b[1;34m(self, field_name, value)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_secure_media(field_name, value)\n\u001b[1;32m---> 68\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caspar\\anaconda3\\envs\\babyjokes\\Lib\\site-packages\\fiftyone\\core\\document.py:74\u001b[0m, in \u001b[0;36m_Document.__setitem__\u001b[1;34m(self, field_name, value)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, field_name, value):\n\u001b[1;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_field\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caspar\\anaconda3\\envs\\babyjokes\\Lib\\site-packages\\fiftyone\\core\\sample.py:120\u001b[0m, in \u001b[0;36m_SampleMixin.set_field\u001b[1;34m(self, field_name, value, create, validate, dynamic)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[0;32m    112\u001b[0m         value,\n\u001b[0;32m    113\u001b[0m         expand_schema\u001b[38;5;241m=\u001b[39mcreate,\n\u001b[0;32m    114\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    115\u001b[0m         dynamic\u001b[38;5;241m=\u001b[39mdynamic,\n\u001b[0;32m    116\u001b[0m     )\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_field\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caspar\\anaconda3\\envs\\babyjokes\\Lib\\site-packages\\fiftyone\\core\\document.py:194\u001b[0m, in \u001b[0;36m_Document.set_field\u001b[1;34m(self, field_name, value, create, validate, dynamic)\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mset_field\u001b[39m(\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    174\u001b[0m     field_name,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    178\u001b[0m     dynamic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    179\u001b[0m ):\n\u001b[0;32m    180\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sets the value of a field of the document.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m        AttirubteError: if the field does not exist and ``create == False``\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_doc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_field\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\caspar\\anaconda3\\envs\\babyjokes\\Lib\\site-packages\\fiftyone\\core\\odm\\mixins.py:141\u001b[0m, in \u001b[0;36mDatasetMixin.set_field\u001b[1;34m(self, field_name, value, create, validate, dynamic)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m validate:\n\u001b[1;32m--> 141\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fields\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfield_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dynamic:\n\u001b[0;32m    144\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_implied_field(\n\u001b[0;32m    145\u001b[0m             field_name,\n\u001b[0;32m    146\u001b[0m             value,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    149\u001b[0m             dynamic\u001b[38;5;241m=\u001b[39mdynamic,\n\u001b[0;32m    150\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\caspar\\anaconda3\\envs\\babyjokes\\Lib\\site-packages\\mongoengine\\fields.py:963\u001b[0m, in \u001b[0;36mListField.validate\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m    961\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make sure that a list of valid fields is being used.\"\"\"\u001b[39;00m\n\u001b[0;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m, BaseQuerySet)):\n\u001b[1;32m--> 963\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOnly lists and tuples may be used in a list field\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    965\u001b[0m \u001b[38;5;66;03m# Validate that max_length is not exceeded.\u001b[39;00m\n\u001b[0;32m    966\u001b[0m \u001b[38;5;66;03m# NOTE It's still possible to bypass this enforcement by using $push.\u001b[39;00m\n\u001b[0;32m    967\u001b[0m \u001b[38;5;66;03m# However, if the document is reloaded after $push and then re-saved,\u001b[39;00m\n\u001b[0;32m    968\u001b[0m \u001b[38;5;66;03m# the validation error will be raised.\u001b[39;00m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_length:\n",
      "File \u001b[1;32mc:\\Users\\caspar\\anaconda3\\envs\\babyjokes\\Lib\\site-packages\\mongoengine\\base\\fields.py:171\u001b[0m, in \u001b[0;36mBaseField.error\u001b[1;34m(self, message, errors, field_name)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raise a ValidationError.\"\"\"\u001b[39;00m\n\u001b[0;32m    170\u001b[0m field_name \u001b[38;5;241m=\u001b[39m field_name \u001b[38;5;28;01mif\u001b[39;00m field_name \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m--> 171\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ValidationError(message, errors\u001b[38;5;241m=\u001b[39merrors, field_name\u001b[38;5;241m=\u001b[39mfield_name)\n",
      "\u001b[1;31mValidationError\u001b[0m: Only lists and tuples may be used in a list field"
     ]
    }
   ],
   "source": [
    "for sample in dataset:\n",
    "    videoname = os.path.basename(sample.filepath)\n",
    "    fps = sample.metadata[\"frame_rate\"]\n",
    "    max_frames = sample.metadata[\"total_frame_count\"]\n",
    "    print(fps)\n",
    "    speechdata = utils.getSpeechData(processedvideos,videoname)\n",
    "    if speechdata is None:\n",
    "        print(f\"Speech data not found for {videoname}\")\n",
    "        continue\n",
    "    phrases = []\n",
    "    for phrase in speechdata[\"segments\"]:\n",
    "        start, end = framerange_from_timestamps([phrase[\"start\"],phrase[\"end\"]], fps, max_frames)\n",
    "        print (start, end)\n",
    "        phrases.append(fo.TemporalDetection(label=phrase[\"text\"],\n",
    "                                        support=[start,end]))\n",
    "        print(phrase[\"text\"])\n",
    "        \n",
    "    sample[\"Speech\"] = fo.TemporalDetections(detections=phrases)\n",
    "    sample[\"Speech\"] = phrases\n",
    "    sample.save()\n",
    "\n",
    "dataset.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Sample: {\n",
      "    'id': '66e1c1ba6baa1cbe4fe48642',\n",
      "    'media_type': 'video',\n",
      "    'filepath': 'C:\\\\Users\\\\caspar\\\\OneDrive\\\\LegoGPI\\\\babyjokes\\\\LookitLaughter.test\\\\2UWdXP.joke1.rep2.take1.Peekaboo.mp4',\n",
      "    'tags': [],\n",
      "    'metadata': <VideoMetadata: {\n",
      "        'size_bytes': 1209336,\n",
      "        'mime_type': 'video/mp4',\n",
      "        'frame_width': 640,\n",
      "        'frame_height': 480,\n",
      "        'frame_rate': 14.29889298892989,\n",
      "        'total_frame_count': 217,\n",
      "        'duration': 15.176,\n",
      "        'encoding_str': 'avc1',\n",
      "    }>,\n",
      "    'JokeType': 'Peekaboo',\n",
      "    'HowFunny': 'Slightly funny',\n",
      "    'LaughYesNo': False,\n",
      "    'ChildSide': None,\n",
      "    'VideoID': '2UWdXP.joke1.rep2.take1.Peekaboo.mp4',\n",
      "    'Speech': [\n",
      "        <TemporalDetection: {\n",
      "            'id': '66e1ca686baa1cbe4fe4cd55',\n",
      "            'tags': [],\n",
      "            'label': ' Hey, excuse me. Look.',\n",
      "            'support': [1, 58],\n",
      "            'confidence': None,\n",
      "        }>,\n",
      "        <TemporalDetection: {\n",
      "            'id': '66e1ca686baa1cbe4fe4cd56',\n",
      "            'tags': [],\n",
      "            'label': \" Ah, I can't handle this.\",\n",
      "            'support': [58, 101],\n",
      "            'confidence': None,\n",
      "        }>,\n",
      "        <TemporalDetection: {\n",
      "            'id': '66e1ca686baa1cbe4fe4cd57',\n",
      "            'tags': [],\n",
      "            'label': \" I'm just going to put it on.\",\n",
      "            'support': [101, 129],\n",
      "            'confidence': None,\n",
      "        }>,\n",
      "        <TemporalDetection: {\n",
      "            'id': '66e1ca686baa1cbe4fe4cd58',\n",
      "            'tags': [],\n",
      "            'label': ' You know, peek-a-boo!',\n",
      "            'support': [129, 158],\n",
      "            'confidence': None,\n",
      "        }>,\n",
      "        <TemporalDetection: {\n",
      "            'id': '66e1ca686baa1cbe4fe4cd59',\n",
      "            'tags': [],\n",
      "            'label': ' Hey.',\n",
      "            'support': [172, 186],\n",
      "            'confidence': None,\n",
      "        }>,\n",
      "    ],\n",
      "    'events': <TemporalDetections: {\n",
      "        'detections': [\n",
      "            <TemporalDetection: {\n",
      "                'id': '66e1d1616baa1cbe4fe4ce5d',\n",
      "                'tags': [],\n",
      "                'label': 'meeting',\n",
      "                'support': [10, 20],\n",
      "                'confidence': None,\n",
      "            }>,\n",
      "            <TemporalDetection: {\n",
      "                'id': '66e1d1616baa1cbe4fe4ce5e',\n",
      "                'tags': [],\n",
      "                'label': 'party',\n",
      "                'support': [30, 60],\n",
      "                'confidence': None,\n",
      "            }>,\n",
      "        ],\n",
      "    }>,\n",
      "    'frames': <Frames: 217>,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "sample = dataset.first()\n",
    "\n",
    "\n",
    "dets =[\n",
    "        fo.TemporalDetection(label=\"meeting\", support=[10, 20]),\n",
    "        fo.TemporalDetection(label=\"party\", support=[30, 60]),\n",
    "    ]\n",
    "\n",
    "sample[\"events\"] = fo.TemporalDetections(\n",
    "    detections= dets\n",
    ")\n",
    "\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in dataset:\n",
    "    videoname = os.path.basename(sample.filepath)\n",
    "    speechdata = utils.getSpeechData(processedvideos,videoname)\n",
    "    if speechdata is None:\n",
    "        print(f\"Speech data not found for {videoname}\")\n",
    "        continue\n",
    "    \n",
    "    subtitles = speechdata[\"segments\"]\n",
    "    # Create a list of text annotations\n",
    "    text_annotations = [\n",
    "        fo.Detection(\n",
    "            text=sub[\"text\"],\n",
    "            start_time=sub[\"start\"],\n",
    "            end_time =sub[\"end\"]\n",
    "        )\n",
    "        for sub in subtitles\n",
    "    ]\n",
    "    sample[\"subtitles\"] = fo.Detections(detections=text_annotations)    \n",
    "    sample.save()\n",
    "\n",
    "14.299\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session.selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#session.selected contains the indices of the dataset samples clicked on in the UI.\n",
    "if len(session.selected) == 0:\n",
    "    print(\"No samples selected. Click the checkbox in the top left of each video to select it.\")\n",
    "else:\n",
    "    print(dataset[session.selected[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 Draw annotated timeline for a select video \n",
    "\n",
    "A group of visualisations to see what happens in a video. \n",
    "\n",
    "In each frame let's find the `centre of gravity` for each person (the average of all the high-confidence marker points). This is handy for time series visualisation. For example plotting the cog.x for each person over time shows how they move closer and further from each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the keypoint data and calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotionColors = {\"angry\":{\"color\":\"red\",\"arousal\":0.9,\"valence\":-0.2},\n",
    "                 \"fear\":{\"color\":\"orange\",\"arousal\":0.2,\"valence\":-0.9},\n",
    "                 \"happy\":{\"color\":\"yellow\",\"arousal\":0.2,\"valence\":0.9},\n",
    "                 \"neutral\":{\"color\":\"grey\",\"arousal\":0,\"valence\":0},\n",
    "                 \"sad\":{\"color\":\"blue\",\"arousal\":-0.2,\"valence\":-0.9},\n",
    "                 \"surprise\":{\"color\":\"green\",\"arousal\":0.9,\"valence\":0.2},\n",
    "                 \"disgust\":{\"color\":\"purple\",\"arousal\":-0.7,\"valence\":-0.7}}\n",
    "who = [\"child\", \"adult\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCoGrav = True\n",
    "plotStDev = True\n",
    "plotSpeech = True\n",
    "plotEmotions = True\n",
    "\n",
    "#numerical sum of boolean flags\n",
    "subplots = sum([plotCoGrav, plotStDev, plotSpeech, plotEmotions])\n",
    "\n",
    "if len(session.selected) == 0:\n",
    "    print(\"No video selected\")\n",
    "    exit()\n",
    "\n",
    "VideoID = dataset[session.selected[0]][\"VideoID\"]\n",
    "keypoints = utils.readKeyPointsFromCSV(processedvideos,VideoID)\n",
    "FPS = utils.getVideoProperty(processedvideos, VideoID, \"FPS\")\n",
    "xmax = keypoints[\"frame\"].max()\n",
    "#this bit of pandas magic calculates average x and y for all the rows.\n",
    "keypoints[[\"cogx\",\"cogy\"]] = keypoints.apply(lambda row: calcs.rowcogs(row.iloc[8:59]), axis=1, result_type='expand')\n",
    "keypoints[[\"stdx\",\"stdy\"]] = keypoints.apply(lambda row: calcs.rowstds(row.iloc[8:59]), axis=1, result_type='expand')\n",
    "\n",
    "#going to add a subplot foe each of the above flags\n",
    "plt.figure(figsize=(20, 5*subplots))\n",
    "plt.suptitle(\"Video Time Line Plots\")\n",
    "pltidx = 0\n",
    "if plotCoGrav:\n",
    "    ax = plt.subplot(subplots, 1, pltidx + 1)\n",
    "    pltidx += 1\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    ax.set_ylabel(\"Horizontal Position\")\n",
    "    ax.set_xlim(0, xmax/FPS)\n",
    "    child = keypoints[keypoints[\"person\"]==\"child\"]\n",
    "    adult = keypoints[keypoints[\"person\"]==\"adult\"]\n",
    "    #a plot of child's centre of gravity frame by frame\n",
    "    childplot = ax.plot(child[\"frame\"], child[\"cogx\"], c=\"red\", alpha=0.5)\n",
    "    ## add line of adult's centre of gravity\n",
    "    adultplot = ax.plot(adult[\"frame\"], adult[\"cogx\"], c=\"blue\", alpha=0.5)\n",
    "    #add legend\n",
    "    ax.legend(['child', 'adult'], loc='upper left')\n",
    "\n",
    "if plotStDev:\n",
    "    ax = plt.subplot(subplots, 1, pltidx + 1)\n",
    "    pltidx += 1\n",
    "    ax.set_xlabel(\"Time (seconds)\")\n",
    "    ax.set_ylabel(\"Horizontal Position\")\n",
    "    ax.set_xlim(0, xmax/FPS)\n",
    "    child = keypoints[keypoints[\"person\"]==\"child\"]\n",
    "    adult = keypoints[keypoints[\"person\"]==\"adult\"]\n",
    "    #a plot of child's centre of gravity frame by frame\n",
    "    childplot = ax.plot(child[\"frame\"], child[\"stdx\"], c=\"red\", alpha=0.5)\n",
    "    ## add line of adult's centre of gravity\n",
    "    adultplot = ax.plot(adult[\"frame\"], adult[\"stdx\"], c=\"blue\", alpha=0.5)\n",
    "    #add legend\n",
    "    ax.legend(['child', 'adult'], loc='upper left')\n",
    "\n",
    "if plotSpeech:\n",
    "    ax2 = plt.subplot(subplots, 1, pltidx + 1)\n",
    "    pltidx += 1\n",
    "    ax2.set_xlabel(\"Time (seconds)\")\n",
    "    ax2.set_ylabel(\"Identified Speech\")\n",
    "    speechjson = utils.getSpeechData(processedvideos,VideoID)\n",
    "    if speechjson is not None:\n",
    "        nsegs = len(speechjson[\"segments\"])\n",
    "        ax2.set_xlim(0, xmax/FPS)\n",
    "        ax2.set_ylim(0, nsegs)\n",
    "        #let's plot the speech segments as boxes\n",
    "        #label each one with the text\n",
    "        for idx, seg in enumerate(speechjson[\"segments\"]):\n",
    "            # #rectangle with the start and end times as x coordinates and nsegs - idx as y coordinates\n",
    "            #fill the rectangle\n",
    "            ax2.fill([seg[\"start\"], seg[\"end\"], seg[\"end\"], seg[\"start\"]], [nsegs - idx - 1, nsegs - idx - 1, nsegs - idx, nsegs - idx], 'r', alpha=0.5)\n",
    "            ax2.text(seg[\"start\"], nsegs- idx -.5 , seg[\"text\"])\n",
    "\n",
    "if plotEmotions:\n",
    "    ax3 = plt.subplot(subplots, 1, pltidx + 1)\n",
    "    pltidx += 1\n",
    "    ax3.set_xlabel(\"Time (seconds)\")\n",
    "    ax3.set_ylim(0, 2)\n",
    "    ax3.set_xlim(0, xmax/FPS)  \n",
    "    emotions = utils.getFaceData(processedvideos,VideoID)\n",
    "    emotions[\"ticker\"] = 1\n",
    "    for index in range(2):\n",
    "        ems = emotions[emotions[\"index\"]==index]\n",
    "        #who is the person we are plotting\n",
    "        # key gives the emotion name, data gives the actual values (also labels)\n",
    "        for key, data in ems.groupby('emotion'):\n",
    "            #plot scatter plot of emotion occurances\n",
    "            ax3.scatter(data[\"frame\"], data[\"ticker\"] + index, label=key, c=emotionColors[key][\"color\"], alpha=0.5, s=100)\n",
    "\n",
    "        \n",
    "    #show legend with emotion colours\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the captions.\n",
    "Go through the speechjson. For each speech segment add a horizotal line with the text. Start and End times from the speechjson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's do a timeline for the emotions of the participants.\n",
    "We'll experiment to find best visualisation. \n",
    "Note this assumes that faces are correctly assigned to correct indviduals. \n",
    "TODO - Code that uses bounding boxes to assign faces to individuals.\n",
    "\n",
    "First we will try a 'scatter' graph. Color coded for each emotion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def scan_folder(source_folder):\n",
    "    data_list = []\n",
    "    id_counter = 1\n",
    "\n",
    "    for root, dirs, files in os.walk(source_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp4'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                audio_path = f\"/data/local-files/?d={file_path}\"\n",
    "                video_path = f\"/data/local-files/?d={file_path}\"\n",
    "\n",
    "                entry = {\n",
    "                    \"id\": id_counter,\n",
    "                    \"data\": {\n",
    "                        \"audio\": audio_path,\n",
    "                        \"video\": video_path\n",
    "                    }\n",
    "                }\n",
    "                data_list.append(entry)\n",
    "                id_counter += 1\n",
    "\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "filejson = scan_folder(r\"C:\\Users\\caspar\\OneDrive\\data\\LookitLaughter.videos\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyjokes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
