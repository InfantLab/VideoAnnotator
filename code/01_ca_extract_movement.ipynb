{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Extract movement and track positions over time.\n",
    "\n",
    "For each video we use YOLOv8 to extract movement data as a set of body keypoints and use its `model.track` method to track individuals over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Video pose estimation with YOLOv8\n",
    "\n",
    "[YOLOv8](https://github.com/ultralytics/ultralytics) is a commercially maintained version of the YOLO object recognition model. [Yolov7](https://github.com/WongKinYiu/yolov7) introduced pose estimation and v8 improves the models and makes everything much more user-friendly. It can be installed as a package\n",
    "\n",
    "* Pip : `pip install ultralytics`\n",
    "* Conda : `conda install -c conda-forge ultralytics`\n",
    "\n",
    "## 1.2 Object tracking \n",
    "\n",
    "YoloV8 also comes with a `model.track` method. This aims to keep track of all identified objects over the course of a video. Let's make use of that to track individuals over time. \n",
    "\n",
    "This is pretty easy instead of calling \n",
    "`results = model(video_path, stream=True)`\n",
    "\n",
    "we can call\n",
    "`results = model.track(video_path, stream=True)`\n",
    "\n",
    "https://docs.ultralytics.com/modes/track/#persisting-tracks-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in = r\"..\\LookitLaughter.test\"\n",
    "metadata_file = \"_LookitLaughter.xlsx\"\n",
    "data_out = r\"..\\data\\1_interim\"\n",
    "\n",
    "#get metadata from excel file\n",
    "metadata = pd.read_excel(os.path.join(videos_in, metadata_file))\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get yolo model with pose estimation\n",
    "model = YOLO('yolov8n-pose.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedvideos = utils.getprocessedvideos(data_out)\n",
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through each row of metadata and\n",
    "#process all related videos\n",
    "forcemetadata = False\n",
    "forceprocess = False\n",
    "tracking = True\n",
    "\n",
    "for index, mrow in metadata.iterrows():\n",
    "    #get VIDEOID from first column of metadata\n",
    "    videoname = mrow[\"VideoID\"]\n",
    "    stemname = os.path.splitext(videoname)[0]\n",
    "    print(f\"video:{videoname}\")\n",
    "\n",
    "    #check we want to refill metadata or this video is not already in processedvideos dataframe\n",
    "    if forcemetadata or videoname not in processedvideos[\"VideoID\"].values: \n",
    "        #use cv2 to get fps and other video info to add to dataframe\n",
    "        cap = cv2.VideoCapture(os.path.join(videos_in,videoname))    \n",
    "        if (cap.isOpened()== False):\n",
    "            print(\"Error opening video stream or file\")\n",
    "            continue\n",
    "        else:\n",
    "            #add row to processedvideos dataframe\n",
    "            row = {\"VideoID\":videoname,\n",
    "                \"ChildID\":mrow[\"ChildID\"],\n",
    "                \"JokeType\":mrow[\"JokeType\"],\n",
    "                \"JokeNum\":mrow[\"JokeNum\"],\n",
    "                \"JokeRep\":mrow[\"JokeRep\"],\n",
    "                \"JokeTake\":mrow[\"JokeTake\"],\n",
    "                \"HowFunny\":mrow[\"HowFunny\"],\n",
    "                \"LaughYesNo\":mrow[\"LaughYesNo\"],\n",
    "                \"Frames\":cap.get(cv2.CAP_PROP_FRAME_COUNT),\n",
    "                \"FPS\":cap.get(cv2.CAP_PROP_FPS) , \n",
    "                \"Width\":cap.get(cv2.CAP_PROP_FRAME_WIDTH), \n",
    "                \"Height\":cap.get(cv2.CAP_PROP_FRAME_HEIGHT), \n",
    "                \"Duration\":cap.get(cv2.CAP_PROP_FRAME_COUNT)/cap.get(cv2.CAP_PROP_FPS)\n",
    "                }\n",
    "            cap.release()\n",
    "            print(f\"Adding video info: {row}\")\n",
    "            newrow = pd.DataFrame(row, index=[0])\n",
    "            processedvideos = pd.concat([processedvideos,newrow], ignore_index=True)\n",
    "\n",
    "    #select the dataframe row for this video \n",
    "    row = processedvideos.loc[processedvideos[\"VideoID\"] == videoname]\n",
    "    #is this video in the processedvideos dataframe?\n",
    "    if row.empty:\n",
    "        print(f\"error: processsedvideos.xlsx has no row for {videoname}\")\n",
    "        continue\n",
    "    #has this video already been processed and can we find the csv file?\n",
    "    if not forceprocess and not pd.isnull(row[\"Keypoints.file\"].values[0]) and os.path.exists(row[\"Keypoints.file\"].values[0]):\n",
    "        print(f\"already processed {videoname} results in {row['Keypoints.file'].values[0]}\")\n",
    "        continue\n",
    "    else:\n",
    "        #use ultralytics YOLO to get keypoints\n",
    "        keypointsdf =utils.videotokeypoints(model, os.path.join(videos_in,videoname) , track = True)\n",
    "        #save keypointsdf as csv    \n",
    "        keypointspath = os.path.join(data_out,  stemname + \".csv\")\n",
    "        keypointsdf.to_csv(keypointspath, index=False)\n",
    "        row[\"Keypoints.file\"] = keypointspath\n",
    "        row[\"Keypoints.when\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
    "        #update this row in processedvideos dataframe\n",
    "        processedvideos.loc[processedvideos[\"VideoID\"] == videoname] = row\n",
    "    \n",
    "    #update processedvideos excel file\n",
    "    utils.saveprocessedvideos(processedvideos, data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a set of normalised keypoint.csv. \n",
    "\n",
    "Every coordinate is scaled to the range [0,1] where 1 === max(frameheight, framewidth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calcs, utils\n",
    "xcols, ycols = utils.getkeypointcols()\n",
    "\n",
    "#Normalise all the x,y coordinates\n",
    "\n",
    "#loop through each row of processedvideos and create a new dataframe & csv file with normalised coordinates\n",
    "for index, row in processedvideos.iterrows():\n",
    "    videoname = row[\"VideoID\"]\n",
    "    keypointsdf = pd.read_csv(row[\"Keypoints.file\"])\n",
    "    normedkeypointsdf = calcs.normaliseCoordinates(keypointsdf, xcols, ycols, row[\"Height\"], row[\"Width\"])\n",
    "    #save keypointsdf as csv\n",
    "    stemname = os.path.splitext(row[\"Keypoints.file\"])[0]\n",
    "    normedkeypointspath = os.path.join(stemname + \"_normed.csv\")\n",
    "    processedvideos.at[index,\"Keypoints.normed\"] = normedkeypointspath\n",
    "    normedkeypointsdf.to_csv(normedkeypointspath, index=False)  \n",
    "\n",
    "\n",
    "utils.saveprocessedvideos(processedvideos, data_out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyjokes-hnIM0ZSK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
