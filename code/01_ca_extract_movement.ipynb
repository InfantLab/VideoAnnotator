{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1.0 Extract movement and track positions over time.\n",
                "\n",
                "For each video we use YOLOv8 to extract movement data as a set of body keypoints and use its `model.track` method to track individuals over time.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1.1 Video pose estimation with Ultralytics YOLO\n",
                "[Ultralytics](https://github.com/ultralytics/ultralytics) is a commercially maintained version of the YOLO object recognition model. [Yolov7](https://github.com/WongKinYiu/yolov7) introduced pose estimation and v8 improves the models and makes everything much more user-friendly. The current version is YOLOv11. It can be installed as a package\n",
                "\n",
                "* Pip : `pip install ultralytics`\n",
                "* Conda : `conda install -c conda-forge ultralytics`\n",
                "\n",
                "## 1.2 Object tracking \n",
                "\n",
                "Since YOLOv8, it also comes with a `model.track` method. This aims to keep track of all identified objects over the course of a video. Let's make use of that to track individuals over time. \n",
                "\n",
                "This is pretty easy instead of calling \n",
                "`results = model(video_path, stream=True)`\n",
                "\n",
                "we can call\n",
                "`results = model.track(video_path, stream=True)`\n",
                "\n",
                "https://docs.ultralytics.com/modes/track/#persisting-tracks-loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import sys\n",
                "\n",
                "project_root = os.path.join(\"..\")\n",
                "sys.path.append(project_root)\n",
                "\n",
                "# Add debug prints to help diagnose the issue\n",
                "print(f\"Current working directory: {os.getcwd()}\")\n",
                "\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Now import project modules\n",
                "from src.utils.io_utils import getProcessedVideos, saveProcessedVideos\n",
                "from src.processors.video_processor import videotokeypoints\n",
                "from src.models.keypoints import get_keypoint_columns\n",
                "from src.utils.keypoint_utils import normalize_keypoints\n",
                "from src.main import process_all_videos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Add these to your imports\n",
                "from src.config import PATH_CONFIG\n",
                "from src.utils.notebook_utils import display_config_info, ensure_dir_exists\n",
                "\n",
                "# Get paths from config\n",
                "videos_in = PATH_CONFIG['videos_in']\n",
                "data_out = PATH_CONFIG['data_out']\n",
                "\n",
                "# Ensure output directory exists\n",
                "if ensure_dir_exists(data_out):\n",
                "    print(f\"Created output directory: {data_out}\")\n",
                "\n",
                "# Display configuration information\n",
                "display_config_info(videos_in, data_out, \"Processing Configuration\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "metadata_file = \"_LookitLaughter.test.xlsx\"\n",
                "\n",
                "#get metadata from excel file\n",
                "metadata = pd.read_excel(os.path.join(videos_in, metadata_file))\n",
                "metadata.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "processedvideos = getProcessedVideos(data_out)\n",
                "processedvideos.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "# Option 1: Process videos using the refactored functions\n",
                "forcemetadata = False\n",
                "forceprocess = False \n",
                "\n",
                "# Process all videos - keep this line the same\n",
                "process_all_videos(videos_in, data_out, metadata_file, forcemetadata, forceprocess)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "processedvideos = getProcessedVideos(data_out)\n",
                "processedvideos.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Create a set of normalised keypoint.csv. \n",
                "\n",
                "For modelling we want all movement data in standardised numerical format.\n",
                "So \n",
                "1. Normalise x, y coordinates. Every coordinate is scaled to the range [0,1] where 1  is (framewidth, frameheight) respectively\n",
                "2. We overwrite the 'person' column [\"child\",\"adult\"] with numerical values [0,1] taken from 'index' column."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# The normalization is now handled in the main process_all_videos function,\n",
                "# but we can also do it separately for each video if needed:\n",
                "\n",
                "processedvideos = getProcessedVideos(data_out)\n",
                "\n",
                "for index, row in processedvideos.iterrows():\n",
                "    if pd.isnull(row.get(\"Keypoints.normed\")) or not os.path.exists(row.get(\"Keypoints.normed\", \"\")):\n",
                "        print(f\"Normalizing keypoints for {row['VideoID']}\")\n",
                "        from src.main import normalize_and_save_keypoints\n",
                "        normalize_and_save_keypoints(row.to_dict(), data_out)\n",
                "    else:\n",
                "        print(f\"Already normalized {row['VideoID']}\")\n",
                "\n",
                "# Refresh the dataframe to see the updated values\n",
                "processedvideos = getProcessedVideos(data_out)\n",
                "processedvideos.head()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "babyjokes",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.5"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
