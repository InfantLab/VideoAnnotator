{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Visualise labelled data and remove artifacts\n",
    "\n",
    "Code that let us overlay each frame of video with outputs from the models. And create time series plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ultralytics.utils as ultrautils\n",
    "import utils\n",
    "import display\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in = os.path.join(\"..\",\"LookitLaughter.test\")\n",
    "demo_data = os.path.join(\"..\",\"data\", \"demo\")\n",
    "temp_out = os.path.join(\"..\",\"data\",\"0_temp\")\n",
    "data_out = os.path.join(\"..\",\"data\",\"1_interim\")\n",
    "videos_out = os.path.join(\"..\",\"data\",\"2_final\")\n",
    "\n",
    "metadata_file = \"_LookitLaughter.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in = os.path.join(\"..\",\"..\",\"LookitLaughter.full.videos\")\n",
    "temp_out = os.path.join(\"..\",\"..\",\"LookitLaughter.full.data\",\"0_temp\")\n",
    "data_out = os.path.join(\"..\",\"..\",\"LookitLaughter.full.data\",\"1_interim\")\n",
    "videos_out = os.path.join(\"..\",\"..\",\"LookitLaughter.full.data\",\"2_final\")\n",
    "\n",
    "metadata_file = \"_LookitLaughter.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'utils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m processedvideos \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241m.\u001b[39mgetProcessedVideos(data_out)\n\u001b[0;32m      2\u001b[0m processedvideos\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'utils' is not defined"
     ]
    }
   ],
   "source": [
    "processedvideos = utils.getProcessedVideos(data_out)\n",
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Add annotations to all vidoes.\n",
    "\n",
    "Generate annotated videos for all videos in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forceAnnotation = False\n",
    "\n",
    "for index, r in processedvideos.iterrows():\n",
    "\n",
    "    videopath = os.path.join(videos_in,r[\"VideoID\"])\n",
    "    videoname = os.path.basename(r[\"VideoID\"])\n",
    "    try: \n",
    "        #let's get all the annotations for this video\n",
    "        kpts = utils.getKeyPoints(processedvideos,videoname)\n",
    "        facedata = utils.getFaceData(processedvideos,videoname)\n",
    "        speechdata = utils.getSpeechData(processedvideos,videoname)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Data error for {videoname}\\n\" + \"Error: \" + str(e))\n",
    "        continue\n",
    "    if forceAnnotation or pd.isnull(r[\"annotatedVideo\"]) or not os.path.exists(r[\"annotatedVideo\"]):\n",
    "        print(f\"Creating annotated video for {videoname}\")\n",
    "        annotatedVideo = display.createAnnotatedVideo(videopath, kpts, facedata, speechdata, temp_out, False)\n",
    "        vidwithaudio = display.addSoundtoVideo(annotatedVideo, r[\"Audio.file\"], videos_out)\n",
    "        r[\"annotatedVideo\"] = vidwithaudio\n",
    "        r[\"annotated.when\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
    "        #update this row in processedvideos dataframe\n",
    "        processedvideos.loc[index] = r\n",
    "    else:\n",
    "        print(f\"Already processed {r['VideoID']}\")\n",
    "\n",
    "#save the processedvideos dataframe\n",
    "utils.saveProcessedVideos(processedvideos, data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#facedata = utils.getFaceData(processedvideos,videoname)\n",
    "videodata = processedvideos[processedvideos[\"VideoID\"] == videoname]\n",
    "if videodata.shape[0] <= 0:\n",
    "    raise FileNotFoundError(f\"No face data file found for {videoname}\")\n",
    "print(f\"We have a face data file for {videoname}\")\n",
    "facesfile = videodata[\"Faces.file\"].values[0]\n",
    "print(facesfile)\n",
    "pd.read_csv(facesfile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2  Correct person labels in all videos.\n",
    "\n",
    "Swap parent and child if these are wrong. Ignore other people in video.\n",
    "\n",
    "In metadata, we have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def keyPointsStdev(df, frames=[], people=\"all\", bodypart=\"whole\"):\n",
    "    \"\"\"find standard deviation of x and y values of keypoints        \n",
    "\n",
    "    args:   df - dataframe of keypoints\n",
    "            frames - list of frames to include\n",
    "            people - list of people to include\n",
    "            bodypart - which bodypart to use, default is \"whole\" for all keypoints\n",
    "    returns:\n",
    "            dataframe of average positions\n",
    "    \"\"\"\n",
    "\n",
    "    if len(frames) == 0:\n",
    "        frames = df.frame.unique()\n",
    "\n",
    "    if people == \"all\":\n",
    "        people = df.person.unique()\n",
    "\n",
    "    if bodypart != \"whole\":\n",
    "        raise NotImplementedError(\"Only whole body implemented for now\")\n",
    "\n",
    "    threshold = 0.5\n",
    "\n",
    "    # create new columns for the centre of gravity\n",
    "    df[\"std.x\"] = np.nan\n",
    "    df[\"std.y\"] = np.nan\n",
    "\n",
    "    for frame in frames:\n",
    "        for person in people:\n",
    "            # get the keypoints for this person in this frame\n",
    "            kpts = df[(df[\"frame\"] == frame) & (df[\"person\"] == person)]\n",
    "\n",
    "            if not kpts.empty:\n",
    "                # get the average position of the bodypart\n",
    "                if bodypart == \"whole\":\n",
    "                    xyc = kpts.iloc[:, 8:59].to_numpy()  # just keypoints\n",
    "                    xyc = xyc.reshape(-1, 3)  # reshape to n x 3 array (x,y,conf\n",
    "                    avgx, avgy = stdevxys(xyc, threshold)\n",
    "\n",
    "                df.loc[\n",
    "                    (df[\"frame\"] == frame) & (df[\"person\"] == person), \"cog.x\"\n",
    "                ] = avgx\n",
    "                df.loc[\n",
    "                    (df[\"frame\"] == frame) & (df[\"person\"] == person), \"cog.y\"\n",
    "                ] = avgy\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyjokes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
