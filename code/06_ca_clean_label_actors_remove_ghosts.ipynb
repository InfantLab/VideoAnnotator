{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Visualise labelled data and remove artifacts\n",
    "\n",
    "Code that let us overlay each frame of video with outputs from the models. And create time series plots. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ultralytics.utils as ultrautils\n",
    "import utils\n",
    "import display\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in = os.path.join(\"..\",\"LookitLaughter.test\")\n",
    "demo_data = os.path.join(\"..\",\"data\", \"demo\")\n",
    "temp_out = os.path.join(\"..\",\"data\",\"0_temp\")\n",
    "data_out = os.path.join(\"..\",\"data\",\"1_interim\")\n",
    "videos_out = os.path.join(\"..\",\"data\",\"2_final\")\n",
    "\n",
    "metadata_file = \"_LookitLaughter.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedvideos = utils.getprocessedvideos(data_out)\n",
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Add annotations to all vidoes.\n",
    "\n",
    "Generate annotated videos for all videos in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forceAnnotation = True\n",
    "\n",
    "for index, r in processedvideos.iterrows():\n",
    "\n",
    "    videopath = os.path.join(videos_in,r[\"VideoID\"])\n",
    "    videoname = os.path.basename(r[\"VideoID\"])\n",
    "    try: \n",
    "        #let's get all the annotations for this video\n",
    "        kpts = utils.getKeyPoints(processedvideos,videoname)\n",
    "        facedata = utils.getFaceData(processedvideos,videoname)\n",
    "        speechdata = utils.getSpeechData(processedvideos,videoname)\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Data error for {videoname}\\n\" + \"Error: \" + str(e))\n",
    "        continue\n",
    "    if forceAnnotation or pd.isnull(r[\"annotatedVideo\"]) or not os.path.exists(r[\"annotatedVideo\"]):\n",
    "        print(f\"Creating annotated video for {videoname}\")\n",
    "        annotatedVideo = display.createAnnotatedVideo(videopath, kpts, facedata, speechdata, temp_out, False)\n",
    "        vidwithaudio = display.addSoundtoVideo(annotatedVideo, r[\"Audio.file\"], videos_out)\n",
    "        r[\"annotatedVideo\"] = vidwithaudio\n",
    "        r[\"annotated.when\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
    "        #update this row in processedvideos dataframe\n",
    "        processedvideos.loc[index] = r\n",
    "    else:\n",
    "        print(f\"Already processed {r['VideoID']}\")\n",
    "\n",
    "#save the processedvideos dataframe\n",
    "utils.saveprocessedvideos(processedvideos, data_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.2 TODO Correct person labels in all videos.\n",
    "\n",
    "Swap parent and child if these are wrong. Ignore other people in video."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyjokes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
