{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d51390f9",
    "language": "markdown"
   },
   "source": [
    "# 5 Extract video understanding\n",
    "\n",
    "We use the [Ask-Anything](https://github.com/OpenGVLab/Ask-Anything) approach to extract a rich descriptiom of the video. Ask Anything calls a range of different computer vision and speech recognition models to extract information from the video. It then passes this information to a large language model (default is ChatGPT) to produce a description. Additional prompt engineering can be added to tailor the description for a specific purpose. The raw information of the component models is also available for further processing. \n",
    "\n",
    "\n",
    "This is based on the \n",
    "\n",
    "https://medium.com/p/c570ab487183\n",
    "\n",
    "## References\n",
    "\n",
    "The Ask-Anything approach is described in the paper [AVideoChat: Chat-Centric Video Understanding](https://arxiv.org/abs/2305.06355). The code is available on [GitHub](https://github.com/OpenGVLab/Ask-Anything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa001",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "# Add the project root to the path so we can import our modules\n",
    "sys.path.append(os.path.join(\"..\", \"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "from src.utils.io_utils import getProcessedVideos, saveProcessedVideos\n",
    "from src.processors.video_understanding import extract_video_understanding\n",
    "from src.main import understand_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa002",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Add these to your imports\n",
    "from src.config import PATH_CONFIG\n",
    "from src.utils.notebook_utils import display_config_info, ensure_dir_exists\n",
    "\n",
    "# Get paths from config\n",
    "videos_in = PATH_CONFIG['videos_in']\n",
    "data_out = PATH_CONFIG['data_out']\n",
    "\n",
    "# Ensure output directory exists\n",
    "if ensure_dir_exists(data_out):\n",
    "    print(f\"Created output directory: {data_out}\")\n",
    "\n",
    "# Display configuration information\n",
    "display_config_info(videos_in, data_out, \"Processing Configuration\")\n",
    "\n",
    "# Get the list of processed videos\n",
    "processedvideos = getProcessedVideos(data_out)\n",
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddd55cbd",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Process all videos to extract understanding\n",
    "understand_videos(videos_in, data_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aa003",
    "language": "python"
   },
   "outputs": [],
   "source": [
    "# Check the updated processed videos dataframe\n",
    "processedvideos = getProcessedVideos(data_out)\n",
    "processedvideos[['VideoID', 'Understanding.file', 'Understanding.when']]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
