{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08 Classify videos by joke type.\n",
    "\n",
    "Each video demonstrates a single joke type. We have this as meta-data. Can we train a classifier based on the movement data?\n",
    "\n",
    "Each video shows one joke from a set of five possibilities [Peekaboo,TearingPaper,NomNomNom,ThatsNotAHat,ThatsNotACat].\n",
    "\n",
    "We will use TensorFlow to train a classifier to predict the joke type from the movement data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import utils\n",
    "import display\n",
    "import calcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Either small demo set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in = os.path.join(\"..\",\"LookitLaughter.test\")\n",
    "demo_data = os.path.join(\"..\",\"data\", \"demo\")\n",
    "temp_out = os.path.join(\"..\",\"data\",\"0_temp\")\n",
    "data_out = os.path.join(\"..\",\"data\",\"1_interim\")\n",
    "videos_out = os.path.join(\"..\",\"data\",\"2_final\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedvideos = utils.getprocessedvideos(data_out)\n",
    "minFrames = processedvideos['Frames'].min()\n",
    "maxFrames = processedvideos['Frames'].max()\n",
    "print(f\"We have {len(processedvideos)} processed videos.\")\n",
    "print(f\"Min Frames: {minFrames}\\nMax Frames: {maxFrames}\")\n",
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendDictToDf(df, dict_to_append):\n",
    "    df = pd.concat([df, pd.DataFrame.from_records(dict_to_append)],ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def padMovementData(keyPoints, maxFrames = None):\n",
    "    \"\"\"\n",
    "    We pad the keyPoints array so that for each person [0,1]:\n",
    "    1. There is a row entry for each frame in the video \n",
    "    2. if the video is less than the maxFrames, we pad out to maxFrames\n",
    "    Nan values are used to pad the array.\n",
    "    \"\"\"\n",
    "    if maxFrames is None:\n",
    "        maxFrames = keyPoints.shape[1]\n",
    "    \n",
    "    # a list of frame numbers\n",
    "    frameNumbers = pd.Index(np.arange(0,maxFrames + 1), name=\"frame\")\n",
    "    \n",
    "    paddedKeyPoints = keyPoints.iloc[:0].copy()\n",
    "    \n",
    "    #There are two people indexed 0 and 1. \n",
    "    #We need to pad both arrays\n",
    "    for idx in range(2):\n",
    "        thisperson = keyPoints[keyPoints[\"index\"]==idx]\n",
    "        missing_frames = frameNumbers.difference(thisperson[\"frame\"])\n",
    "        \n",
    "        add_df = pd.DataFrame(index=missing_frames, columns=thisperson.columns).fillna(np.nan)\n",
    "        add_df[\"frame\"] = missing_frames\n",
    "        add_df[\"index\"] = idx\n",
    "        add_df[\"person\"] = idx\n",
    "        thisperson = pd.concat([thisperson, add_df])\n",
    "        # add the paddedKeyPoints to the dataframe\n",
    "        paddedKeyPoints = appendDictToDf(paddedKeyPoints,thisperson)\n",
    "        \n",
    "    return paddedKeyPoints.sort_values(by=[\"frame\",\"index\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolateMovementData(keyPoints):\n",
    "    \"\"\"\n",
    "    We interpolate the keyPoints array so that for each person [0,1]:\n",
    "    1. There is a row entry for each frame in the video \n",
    "    2. if the video is less than the maxFrames, we pad out to maxFrames\n",
    "    Nan values are used to pad the array.\n",
    "    \"\"\"\n",
    "    # a list of frame numbers\n",
    "    frameNumbers = pd.Index(np.arange(0,maxFrames + 1), name=\"frame\")\n",
    "    \n",
    "    interpolatedKeyPoints = keyPoints.iloc[:0].copy()\n",
    "    \n",
    "    #There are two people indexed 0 and 1. \n",
    "    #We need to interpolate both arrays\n",
    "    for idx in range(2):\n",
    "        thisperson = keyPoints[keyPoints[\"index\"]==idx]\n",
    "        thisperson = thisperson.set_index(\"frame\")\n",
    "        thisperson = thisperson.reindex(frameNumbers)\n",
    "        thisperson = thisperson.interpolate(method='linear',axis=0,limit_direction='backward')\n",
    "        thisperson[\"frame\"] = thisperson.index\n",
    "        thisperson[\"index\"] = idx\n",
    "        thisperson[\"person\"] = idx\n",
    "        # add the paddedKeyPoints to the dataframe\n",
    "        interpolatedKeyPoints = appendDictToDf(interpolatedKeyPoints,thisperson)\n",
    "        \n",
    "    return interpolatedKeyPoints.sort_values(by=[\"frame\",\"index\"])\n",
    "\n",
    "def flattenMovementDataset(kps):\n",
    "    \"\"\"\n",
    "    We flatten the movement dataset so that each row is a frame for both people.\n",
    "    \"\"\"\n",
    "    #There are two people indexed 0 and 1. \n",
    "    #We w\n",
    "    flattenedKps = kps.pivot(index='frame', columns='index')\n",
    "    flattenedKps.columns = [\"_\".join((str(j),i)) for i,j in flattenedKps.columns]\n",
    "    flattenedKps = flattenedKps.reset_index()\n",
    "    return flattenedKps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kps = utils.readKeyPointsFromCSV(processedvideos,VIDEO_FILE,True)\n",
    " \n",
    "paddedKps = padMovementData(kps, 400)\n",
    "paddedKps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolatedKps = interpolateMovementData(paddedKps)\n",
    "interpolatedKps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMovementDataset(processedVideos):\n",
    "    dataset = []\n",
    "    labels = []\n",
    "    # for each row of processedVideos, we add one timeseries to the dataset\n",
    "    for index, r in processedvideos.iterrows():\n",
    "        df = pd.read_csv(r['Keypoints.normed'])\n",
    "        df = padMovementData(df, maxFrames)\n",
    "        df = interpolateMovementData(df)\n",
    "        df = df.replace(np.nan, 0)\n",
    "        df = flattenMovementDataset(df)\n",
    "        \n",
    "        features = tf.convert_to_tensor(df.values, dtype=tf.float32)\n",
    "        label = r[\"Joke.Label\"]\n",
    "        dataset.append(features)\n",
    "        labels.append(label)\n",
    "    \n",
    "    \n",
    "    return tf.data.Dataset.from_tensor_slices((dataset, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattenedKps = flattenMovementDataset(interpolatedKps)\n",
    "flattenedKps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfdataset = createMovementDataset(processedvideos)\n",
    "\n",
    "train, test = tf.keras.utils.split_dataset(tfdataset, left_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first element of dataset so we can grab its dimensions\n",
    "keyPoints = next(iter(train))[0]\n",
    "\n",
    "#let's build a simple model\n",
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(keyPoints.shape[0], keyPoints.shape[1])),\n",
    "    layers.LSTM(8),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "              sample_weight_mode='temporal',\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=[tf.metrics.MeanAbsoluteError()])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train.batch(32), epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's evaluate the model\n",
    "model.evaluate(test.batch(32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
