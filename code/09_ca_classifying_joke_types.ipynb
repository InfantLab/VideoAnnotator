{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09 Classify videos by joke type.\n",
    "\n",
    "Each video demonstrates a single joke type. We have this as meta-data. Can we train a classifier based on the movement data?\n",
    "\n",
    "Each video shows one joke from a set of five possibilities [Peekaboo,TearingPaper,NomNomNom,ThatsNotAHat,ThatsNotACat].\n",
    "\n",
    "We will use TensorFlow to train a classifier to predict the joke type from the movement data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Make numpy values easier to read.\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# local imports\n",
    "import utils\n",
    "import display\n",
    "import calcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Load the data\n",
    "\n",
    "### Use either small demo \n",
    "Consists of 54 videos. From 4 families (parent and baby) demoing five jokes three times each. (Some missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in = os.path.join(\"..\",\"LookitLaughter.test\")\n",
    "demo_data = os.path.join(\"..\",\"data\", \"demo\")\n",
    "temp_out = os.path.join(\"..\",\"data\",\"0_temp\")\n",
    "data_out = os.path.join(\"..\",\"data\",\"1_interim\")\n",
    "videos_out = os.path.join(\"..\",\"data\",\"2_final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or the Full set\n",
    "\n",
    "Consists of 1425 videos. From 90 familes (parent and baby) demoing approximately five jokes three times each. Some repetitions and omissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in = os.path.join(\"..\",\"..\",\"LookitLaughter.full.videos\")\n",
    "temp_out = os.path.join(\"..\",\"..\",\"LookitLaughter.full.data\",\"0_temp\")\n",
    "data_out = os.path.join(\"..\",\"..\",\"LookitLaughter.full.data\",\"1_interim\")\n",
    "videos_out = os.path.join(\"..\",\"..\",\"LookitLaughter.full.data\",\"2_final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedVideos = utils.getProcessedVideos(data_out)\n",
    "minFrames = processedVideos['Frames'].min()\n",
    "maxFrames = processedVideos['Frames'].max()\n",
    "print(f\"We have {len(processedVideos)} processed videos.\")\n",
    "print(f\"Min Frames: {minFrames}\\nMax Frames: {maxFrames}\")\n",
    "processedVideos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use matplotlib to draw histograam of number of frames\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(processedVideos['Frames'], bins=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Load and preprocess the data\n",
    "\n",
    "1. Load normed movement data. \n",
    "2. Exclude videos shorter than a min length\n",
    "3. Pad all sequences to the same max length. \n",
    "4. Interpolate missing values (up to last frame of real data).\n",
    "5. Replace final missing values with zeros.\n",
    "6. Add to tf.data.Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createMovementDataset(processedVideos, minFrames = 0, maxFrames = None, ragged = False):\n",
    "    \"\"\"\n",
    "    Creates a movement dataset from processed videos.\n",
    "\n",
    "    Args:\n",
    "        processedVideos (pandas.DataFrame): A DataFrame containing processed video data.\n",
    "        minFrames (int, optional): Rows with less than minframes are excluded. Defaults to 0 (include all frames.)\n",
    "        maxFrames (int, optional): Data padded or truncated to have maxFrames. Defaults to max of all videos.\n",
    "        ragged (bool, optional): Whether to create a ragged tensor. Defaults to False (TODO: not implemented yet)\n",
    "\n",
    "    Returns:\n",
    "        tf.data.Dataset: A TensorFlow Dataset containing features and labels.\n",
    "    \"\"\"\n",
    "    if maxFrames is None:\n",
    "        maxFrames = processedVideos[\"Frames\"].max()\n",
    "    if ragged:\n",
    "        raise NotImplementedError(\"Ragged tensors not implemented yet.\")    \n",
    "    dataset = []\n",
    "    labels = []\n",
    "    # for each row of processedVideos, we add one timeseries to the dataset\n",
    "    for index, r in processedVideos.iterrows():\n",
    "        df = pd.read_csv(r['Keypoints.normed'])\n",
    "        if r[\"Frames\"] < minFrames:\n",
    "            continue\n",
    "        df = utils.padMovementData(df, maxFrames)\n",
    "        df = utils.interpolateMovementData(df)\n",
    "        df = df.replace(np.nan, 0)\n",
    "        df = utils.flattenMovementDataset(df)\n",
    "        \n",
    "        features = tf.convert_to_tensor(df.values, dtype=tf.float32)\n",
    "        label = r[\"Joke.Label\"]\n",
    "        dataset.append(features)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return tf.data.Dataset.from_tensor_slices((dataset, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainMinFrames = 100\n",
    "trainMaxFrames = 1000   \n",
    "tfdataset = createMovementDataset(processedVideos,trainMinFrames,trainMaxFrames)\n",
    "\n",
    "train, test = tf.keras.utils.split_dataset(tfdataset, left_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get first element of dataset so we can grab its dimensions\n",
    "keyPoints = next(iter(train))[0]\n",
    "\n",
    "#let's build a simple model\n",
    "model.compile(loss=tf.losses.MeanSquaredError(),\n",
    "              optimizer=tf.optimizers.Adam(),\n",
    "              metrics=[tf.metrics.MeanAbsoluteError()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's evaluate the model\n",
    "model.evaluate(test.batch(32))\n",
    "\n",
    "#table of predictions\n",
    "predictions = model.predict(test.batch(32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
