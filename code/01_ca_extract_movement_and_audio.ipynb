{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Extract movement and track positions over time.\n",
    "\n",
    "For each video we use YOLOv8 to extract movement data as a set of body keypoints and use its `model.track` method to track individuals over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Video pose estimation with YOLOv8\n",
    "\n",
    "[YOLOv8](https://github.com/ultralytics/ultralytics) is a commercially maintained version of the YOLO object recognition model. [Yolov7](https://github.com/WongKinYiu/yolov7) introduced pose estimation and v8 improves the models and makes everything much more user-friendly. It can be installed as a package\n",
    "\n",
    "* Pip : `pip install ultralytics`\n",
    "* Conda : `conda install -c conda-forge ultralytics`\n",
    "\n",
    "## 1.2 Object tracking \n",
    "\n",
    "YoloV8 also comes with a `model.track` method. This aims to keep track of all identified objects over the course of a video. Let's make use of that. \n",
    "\n",
    "This is pretty easy instead of calling \n",
    "`results = model(video_path, stream=True)`\n",
    "\n",
    "we can call\n",
    "`results = model.track(video_path, stream=True)`\n",
    "\n",
    "https://docs.ultralytics.com/modes/track/#persisting-tracks-loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_in = r\"..\\LookitLaughter.test\"\n",
    "metadata_file = \"_LookitLaughter.xlsx\"\n",
    "data_out = r\"..\\data\\1_interim\"\n",
    "\n",
    "#a couple of files for testing\n",
    "VIDEO_FILE  = os.path.join(videos_in, \"2UWdXP.joke1.rep2.take1.Peekaboo.mp4\")\n",
    "VIDEO_FILE2 = os.path.join(videos_in, \"2UWdXP.joke2.rep1.take1.NomNomNom.mp4\")\n",
    "\n",
    "testset = [VIDEO_FILE, VIDEO_FILE2] \n",
    "\n",
    "#get metadata from excel file\n",
    "metadata = pd.read_excel(os.path.join(videos_in, metadata_file))\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get yolo model with pose estimation\n",
    "model = YOLO('yolov8n-pose.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processedvideos = utils.getprocessedvideos(data_out)\n",
    "processedvideos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through each row of metadata and\n",
    "#process all related videos\n",
    "forcemetadata = False\n",
    "forceprocess = True\n",
    "tracking = True\n",
    "\n",
    "for index, mrow in metadata.iterrows():\n",
    "    #get VIDEOID from first column of metadata\n",
    "    videoname = mrow[\"VideoID\"]\n",
    "    stemname = os.path.splitext(videoname)[0]\n",
    "    print(f\"video:{videoname}\")\n",
    "\n",
    "    #check we want to refill metadata or this video is not already in processedvideos dataframe\n",
    "    if forcemetadata or videoname not in processedvideos[\"VideoID\"].values: \n",
    "        #use cv2 to get fps and other video info to add to dataframe\n",
    "        cap = cv2.VideoCapture(os.path.join(videos_in,videoname))    \n",
    "        if (cap.isOpened()== False):\n",
    "            print(\"Error opening video stream or file\")\n",
    "            continue\n",
    "        else:\n",
    "            #add row to processedvideos dataframe\n",
    "            row = {\"VideoID\":videoname,\n",
    "                \"ChildID\":mrow[\"ChildID\"],\n",
    "                \"JokeType\":mrow[\"JokeType\"],\n",
    "                \"JokeNum\":mrow[\"JokeNum\"],\n",
    "                \"JokeRep\":mrow[\"JokeRep\"],\n",
    "                \"JokeTake\":mrow[\"JokeTake\"],\n",
    "                \"HowFunny\":mrow[\"HowFunny\"],\n",
    "                \"LaughYesNo\":mrow[\"LaughYesNo\"],\n",
    "                \"Frames\":cap.get(cv2.CAP_PROP_FRAME_COUNT),\n",
    "                \"FPS\":cap.get(cv2.CAP_PROP_FPS) , \n",
    "                \"Width\":cap.get(cv2.CAP_PROP_FRAME_WIDTH), \n",
    "                \"Height\":cap.get(cv2.CAP_PROP_FRAME_HEIGHT), \n",
    "                \"Duration\":cap.get(cv2.CAP_PROP_FRAME_COUNT)/cap.get(cv2.CAP_PROP_FPS)\n",
    "                }\n",
    "            cap.release()\n",
    "            print(f\"Adding video info: {row}\")\n",
    "            newrow = pd.DataFrame(row, index=[0])\n",
    "            processedvideos = pd.concat([processedvideos,newrow], ignore_index=True)\n",
    "\n",
    "    #select the dataframe row for this video \n",
    "    row = processedvideos.loc[processedvideos[\"VideoID\"] == videoname]\n",
    "    #check if we have already processed this video is keypoints is not nan\n",
    "    if row.empty:\n",
    "        print(f\"error: no row for {videoname}\")\n",
    "        continue\n",
    "    elif not forceprocess and not pd.isnull(row[\"Keypoints.file\"].values[0]):\n",
    "        print(row[\"Keypoints.file\"].values[0]  )\n",
    "        print(f\"already processed {videoname}\")\n",
    "        continue\n",
    "    else:\n",
    "        #use ultralytics YOLO to get keypoints\n",
    "        keypointsdf =utils.videotokeypoints(model, os.path.join(videos_in,videoname) , track = True)\n",
    "        #save keypointsdf as csv    \n",
    "        keypointspath = data_out + \"\\\\\" + stemname + \".csv\"\n",
    "        keypointsdf.to_csv(keypointspath)\n",
    "        row[\"Keypoints.file\"] = keypointspath\n",
    "        row[\"Keypoints.when\"] = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.gmtime())\n",
    "        #update this row in processedvideos dataframe\n",
    "        processedvideos.loc[processedvideos[\"VideoID\"] == videoname] = row\n",
    "    \n",
    "\n",
    "    #update processedvideos excel file\n",
    "    processedvideos.to_excel(data_out + \"\\\\processedvideos.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's test it out first\n",
    "\n",
    "# Open the video file\n",
    "video_path = VIDEO_FILE\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "        results = model.track(frame, persist=True)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's have a look at the results object for video \n",
    "\n",
    "results = model.track(VIDEO_FILE,stream=True)  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "babyjokes-hnIM0ZSK",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
