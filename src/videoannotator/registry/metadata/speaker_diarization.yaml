name: speaker_diarization
display_name: Speaker Diarization
description: Speaker diarization using PyAnnote.audio to segment and identify different speakers with timestamps, producing RTTM format output.
pipeline_family: audio
variant: pyannote
tasks:
  - speaker-diarization
  - speaker-segmentation
modalities:
  - audio
capabilities:
  - timeline
  - speaker-turns
outputs:
  - format: RTTM
    types: [speaker_turns]
config_schema:
  model:
    type: string
    default: pyannote/speaker-diarization-3.1
    description: PyAnnote model identifier from HuggingFace
  min_speakers:
    type: integer
    default: 1
    description: Minimum number of speakers to consider
  max_speakers:
    type: integer
    default: 10
    description: Maximum number of speakers to consider
  use_auth_token:
    type: boolean
    default: true
    description: Use HuggingFace authentication token (required for PyAnnote models)
examples:
  - cli: videoannotator job submit demo.mp4 --pipelines speaker_diarization
    description: Submit speaker diarization job
  - api: |
      {
        "video_url": "demo.mp4",
        "pipelines": ["speaker_diarization"],
        "config": {
          "speaker_diarization": {
            "min_speakers": 2,
            "max_speakers": 5
          }
        }
      }
    description: Diarization with 2-5 speakers via API
version: 1
stability: stable
backends:
  - pytorch
requirements:
  environment:
    - HF_AUTH_TOKEN: HuggingFace authentication token for PyAnnote models
  packages:
    - pyannote.audio>=3.0
