# VideoAnnotator Production Docker Image - GPU Version
# This image does NOT include models/weights - they download automatically on first use
#
# Usage:
#   docker build -f Dockerfile.gpu -t videoannotator:gpu .
#   docker run --gpus all --rm -p 8000:8000 -v ${PWD}/data:/app/data videoannotator:gpu

FROM nvidia/cuda:12.6.0-runtime-ubuntu24.04

SHELL ["/bin/bash","-lc"]
RUN apt-get update && apt-get install -y \
    curl python3 python3-venv python3-pip git \
    libgl1-mesa-dri libglib2.0-0 libsm6 libxext6 libxrender1 libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# Ensure locale is generated so LANG=en_US.UTF-8 works inside the container
RUN apt-get update && apt-get install -y locales \
    && locale-gen en_US.UTF-8 \
    && update-locale LANG=en_US.UTF-8 LC_ALL=en_US.UTF-8 \
    && rm -rf /var/lib/apt/lists/*

# Export UTF-8 locale for all processes
ENV LANG=en_US.UTF-8
ENV LC_ALL=en_US.UTF-8

# uv package manager
RUN curl -LsSf https://astral.sh/uv/install.sh | sh
ENV PATH="/root/.local/bin:${PATH}"

WORKDIR /app

# Build args to allow dev builds to skip network-heavy steps (defaults: true)
# For production image builds set these to "false" to perform installs in image.
ARG SKIP_IMAGE_UV_SYNC=true
ARG SKIP_TORCH_INSTALL=true

# Copy source code (excluding models via .dockerignore)
# Copy project files (excluded items controlled by .dockerignore)
COPY . .

# Install dependencies (excluding torch to avoid conflicts)
# These steps can be skipped at build time for dev containers by setting
# build args SKIP_IMAGE_UV_SYNC=true and SKIP_TORCH_INSTALL=true. Post-create
# commands will run `uv sync` inside the running container where network is
# usually available.
RUN if [ "${SKIP_IMAGE_UV_SYNC}" != "true" ]; then uv sync --frozen --no-editable; else echo "[BUILD] Skipping uv sync at image build (SKIP_IMAGE_UV_SYNC=true)"; fi

# Install CUDA PyTorch for GPU acceleration (override CPU version)
RUN if [ "${SKIP_TORCH_INSTALL}" != "true" ]; then uv pip install "torch==2.8.0+cu126" "torchvision==0.23.0+cu126" "torchaudio==2.8.0+cu126" --index-url https://download.pytorch.org/whl/cu126; else echo "[BUILD] Skipping torch install at image build (SKIP_TORCH_INSTALL=true)"; fi

# Verify GPU access (no model downloading needed!)
RUN uv run python3 -c "import torch; print(f'[GPU BUILD] CUDA available: {torch.cuda.is_available()}'); print(f'[GPU BUILD] PyTorch version: {torch.__version__}'); print('[GPU BUILD] Production image ready - models will download on first use')"

# Set environment for production
ENV PYTHONUNBUFFERED=1
ENV CUDA_VISIBLE_DEVICES=0

# Create directories for mounted volumes
RUN mkdir -p /app/data /app/output /app/logs

EXPOSE 8000

CMD ["uv", "run", "python3", "api_server.py", "--log-level", "info"]